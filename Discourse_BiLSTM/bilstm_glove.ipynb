{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bilstm_glove.ipynb","provenance":[{"file_id":"1IpfMkmtFHT_w4HBS3uNOGM26Apw0aZVz","timestamp":1581183772457},{"file_id":"1Om7GVDag19A4DMFLrCW1n1Lq1XjSr_j9","timestamp":1580323733414}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNvz5a/IpQtJfWaVB0muGbV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yi1b9Svhk-Qy","colab_type":"code","outputId":"f025e680-ed4e-4453-f292-6c49836c4560","executionInfo":{"status":"ok","timestamp":1581413028144,"user_tz":-330,"elapsed":25879,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WN6w7wL-b-eI","colab_type":"code","outputId":"22c5acf2-07c6-4643-9685-8aca0fcc5bb2","executionInfo":{"status":"ok","timestamp":1581413028147,"user_tz":-330,"elapsed":3649,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My\\ Drive/NLP/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/NLP\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1BWsbXx2sziz","colab_type":"code","outputId":"d8eaa85b-04ca-4225-9348-dbb9e5fed191","executionInfo":{"status":"ok","timestamp":1581413036297,"user_tz":-330,"elapsed":11024,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["ls data"],"execution_count":4,"outputs":[{"output_type":"stream","text":["bilstm_label.list                                    mapping_bilstm.list\n","causal_explanation_200_da_embedding_seqs_glove.list  processed_train.npy\n","custom_mapping_bilstm.list                           \u001b[0m\u001b[01;34mSubtask-1-master\u001b[0m/\n","glove.6B.300d.txt                                    \u001b[01;34mSubtask-2-master\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hy0G-z3qtS7W","colab_type":"code","outputId":"98e9b31a-16f9-44d9-d12d-34d25e6f8b40","executionInfo":{"status":"ok","timestamp":1581362040471,"user_tz":-330,"elapsed":10601,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk import pos_tag\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.preprocessing import LabelEncoder\n","from collections import defaultdict\n","from nltk.corpus import wordnet as wn\n","import numpy as np\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('stopwords')\n","\n","np.random.seed(500)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zeZbGHV0vqq1","colab_type":"code","colab":{}},"source":["path = \"data/processed_train.npy\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s32lx-TucJsn","colab_type":"code","colab":{}},"source":["corpus = np.load(path, allow_pickle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSX3oy6zcQzz","colab_type":"code","colab":{}},"source":["for i in range(len(corpus)):\n","  corpus[i]['args'] = [word_tokenize(sent.lower()) for sent in corpus[i]['args']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGyKQsjswY-0","colab_type":"code","colab":{}},"source":["# glove\n","\n","w2v = []\n","w2i = {}\n","words = []\n","\n","idx = 0\n","with open('data/glove.6B.300d.txt','rb') as f:\n","  for l in f:\n","    line = l.decode().split()\n","    word =  line[0]\n","    words.append(word)\n","    w2i[word] = idx\n","    idx +=1\n","    vect = np.array(line[1:]).astype(np.float)\n","    w2v.append(vect)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYvk9ssU4_mS","colab_type":"code","colab":{}},"source":["for i in range(len(corpus)):\n","  disc = corpus[i]['args']\n","  for k in range(len(disc)):\n","    sent = disc[k]\n","    for j in range(len(sent)):\n","      if '...' in sent[j]:\n","        corpus[i]['args'][k][j] = sent[j].replace('...','')\n","      if '..' in sent[j]:\n","        corpus[i]['args'][k][j] = sent[j].replace('..','')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kff8lmP5BThE","colab_type":"code","colab":{}},"source":["for i in range(len(corpus)):\n","  disc = corpus[i]['args']\n","  for k in range(len(disc)):\n","    sent = disc[k]\n","    for j in range(len(sent)):\n","      if '-' in sent[j]:\n","        x = sent[j].split('-')\n","        corpus[i]['args'][k][j] = x[0]\n","        if j+1 == len(sent):\n","          corpus[i]['args'][k].append(x[1])\n","        else:\n","          corpus[i]['args'][k].insert(j+1,x[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"668r-osICj4s","colab_type":"code","colab":{}},"source":["for i in range(len(corpus)):\n","  disc = corpus[i]['args']\n","  for k in range(len(disc)):\n","    for j in range(len(sent)):\n","      if '/' in sent[j]:\n","        x = sent[j].split('/')\n","        corpus[i]['args'][k][j] = x[0]\n","        if len(x)>1:\n","          corpus[i]['args'][k].insert(j+1,x[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8WVCaYeC_rl","colab_type":"code","colab":{}},"source":["for i in range(len(corpus)):\n","  disc = corpus[i]['args']\n","  for k in range(len(disc)):\n","    for j in range(len(sent)):\n","      if \"'\" in sent[j]:\n","        if sent[j] not in words:\n","          corpus[i]['args'][k][j] = sent[j].replace(\"'\",\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pKHBegoNEXZa","colab_type":"code","colab":{}},"source":["for i in range(len(corpus)):\n","  disc = corpus[i]['args']\n","  for k in range(len(disc)):\n","    for j in range(len(sent)):\n","      if \".\" in sent[j]:\n","        if sent[j] not in words:\n","          if len(sent[j].split('.')) > 2 or len(sent[j].split('.')) == 1:\n","            corpus[i]['args'][k][j] = sent[j].replace(\".\",\"\")\n","          else:\n","            if len(sent[j].split('.')) == 2:\n","              x = sent[j].split('.')\n","              corpus[i]['args'][k][j] = x[0]\n","              corpus[i]['args'][k].insert(j+1, x[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UcYTE0JpxTs7","colab_type":"code","colab":{}},"source":["not_in = []\n","for element in corpus:\n","  for sent in element['args']:\n","    for word in sent:\n","      if word not in words:\n","        if word not in not_in:\n","          not_in.append(word)\n","        # print(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dspSDLi08Lz","colab_type":"code","outputId":"fc9e5364-b052-4923-d4e6-b24b5c0128fd","executionInfo":{"status":"ok","timestamp":1581362201482,"user_tz":-330,"elapsed":127,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(not_in)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1464"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"kicQpyKfE2Ps","colab_type":"code","outputId":"ea6c489f-caca-4a36-db98-ea091664ac1c","executionInfo":{"status":"ok","timestamp":1581362201485,"user_tz":-330,"elapsed":66,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(not_in)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["['', 'kingdomof', 'forwardnot', 'stakethe', 'c.d.c', 'nonemergencies', 'circumastance', 'reynaga', 'irisin', 'cuntry', '//bit.ly/1t9z8qd', 'shkreli', 'thatdespite', 'forcehe', 'ntgr', 'bfsr', 'ceramides', 'otillar', 'scratchpad', 'mcritchie', 'enria', 'watchwordalthough', 'mosychuk', 'aedpa', 'dipierro', 'i.v.g', 'panelo', 'arconic', 'paynet', 'gorsuchs', 'suicidenow', 'kyrsten', 'freiborg', '5bn', 'depomed', 'amsellem', 'overperformances', 'thcb', 'privitera', 'legimately', 'burkan', 'zonszein', '10,554', 'brochez', 'h.i.v', 'pfapa', 'bingener', 'entresto', 'candidateand', 'f.d.a', 'zarxio', 'tdn2', 'confounders', 'ba.n', 'overcounted', 'rebirthed', 'altmaier', 'barcap', 'shithole', 'lignos', 'sciple', 'morens', 'd.e.a', 'reclosing', 'roadfor', 'unpeg', 'currencythe', 'somepart', 'allthat', 'staehr', 'baumblit', 'khorsand', 'innereye', 'topkill', 'kilimnik', 'fralick', 'krautzberger', 'truog', 'luján', 'screenos', 'unbooked', 'ohions', 'sowanick', 'neurobiologically', 'killino', 'incel', 'nn27303398', 'rcep', 'piampongsant', 'oubina', 'nontraumatic', '21e', 'coeure', 'rabten', 'reichlin', 'klipp', 'theranos', 'brexit', 'ionis', 'msct', '≥25kg', '≥30kg', 'müller', 'issakainen', 'blasey', 'elugardo', 'unrigging', '40bn', '100tn', 'deprescribing', 'mulye', 'ilbd', 'torba', 'shiono', 'vemurafenib', 'dacarbazine', 'lynparza', 'nrk.l', 'cholnoky', 'jeoff', 'gangwisch', '445.4', '2010.se', 'pended', 'rejoiceit', 'staikouras', 'lewandowskis', 'carcinoembryonic', 'bosiers', 'a.z', 'haridy', 'urodynamic', 'alembik', 'clr.n', 'dvn.n', 'mro.n', 'melland', 'florange', 'brexiteer', 'bsc.n', 'colectomy', 'pay+', 'rosanoff', 'knols', 'jobsbut', 'siloed', 'preauthorization', 'b.d.s.m', 'gaddie', 'mansplaining', 'esiner', 'ead.pa', 'beggaring', 'iezzi', '60tn', 'townswick', 'guidancesome', 'icagen', 'ecohelmet', '�', 'fscai', 'scai', 'schnautz', 'proration', 'incentivised', 'mdv3100', 'zytiga', 'medivation', 'melsen', 'nunamaker', 'tudose', 'shingrix', 'indexuniverse', 'vxx', 'washpost', 'karoun', 'securityholder', 'yger', 'google+', '.dji', '11,493.72', 'o.k', 'certifiied', 'orkambi', 'f.b.i', 'en+', 'pshg_p', '112bn', 'slavedriver', 'isrg', 'sharice', 'jfcom', 'woahhhh', 'nktr', 'opdivo', 'yervoy', 'immunotherapies', 'recapitalizating', 'dierksen', 'ambarella', 'gamblersor', 'contestantsthat', 'schreckreports', 'erdogans', 'beencooked', 'golbon', 'eubut', 'clintonness', 'giunchigliani', 'eteplirsen', 'storiesseasonal', 'viprinex', 'avenatti', 'jarris', 'gilholm', 'nontradeable', 'oanda', 'h.r', 'prizeroot', 'systemthe', 'pescanova', 'weekdo', 'unsterilised', 'zemcik', 'immunochemical', 'papyracea', 'morcellation', 'houte', 'firdapse', 'kronthal', 'passporting', 'rotasiil', 'patrikis', 'cyad', 'comeyi', 'misdemeanourand', 'lomen', 'hoerth', 'baxalta', 'engag', 'percec', 'dovere', '1/33', 'provention', 't1d', 'zavecz', 'hoepa', 'inquicker', 'baytex', 'appearance.', 'whcra', 'wharen', 'randomising', 'analogise', 'thoughtssome', 'assetswhich', 'banksthe', 'fibrillating', 'defibrillated', 'conlumino', 'slutkin', 'tjokrosaputro', 'dailyfx.com', 'ohiohealth', 'littlefinger', 'monologuing', 'dontos', 'lemtrada', '747.5', 'presal', 'hematospermia', 'guindos', 'continueon', 'trueness', 'queered', 'nfld', 'venoplasty', 'unbuyable', 'btig', 'kopola', 'mäkinen', '33bn', '2.7bn', 'mythaholic', 'venge', 'm.r.i', 'scardina', 'isis8', \"whad'ya\", '7.6bn', '23bn', 'misgoverning', 'tyrannically', 'sobanko', 'filmalter', 'f.e.c', 'c.c.r.c', '3.3bn', 'investmentwhile', 'wordelectoral', 'healthkit', 'parscale', 'ransomware', 'zulily', 'd.n.c', 'léonora', 'chiappelli', 'wmt.n', 'tgt.n', 'vestager', 'agentswho', 'jobfeared', 'dehejia', 'idfc', 'thepast', 'thatbehaviourright', '//bit.ly/2gehtaq', 'wauthier', 'cubicin', 'otezla', 'receptos', 'lunacies', 'coxibs', 'xme', 'thiswhile', 'hq2', 'catellanos', 'indivior', 'durata', 'sciutto', 'bigotted', 'lamestream', 'starndard', 'lifepoint', 'lpnt.o', 'hma.n', 'ridaforolimus', 'mortifications', 'chozick', 'cyberespionage', 'alperovitch', 'crowdstrike', 'hackable', 'nkc', 'jcar015', '69.4bn', '132.06', '130.57', 'fornero', 'circumsized', 'pneumoliner', 'morcellated', 'inácio', 'bromiley', 'storiesempty', 'bakries', 'daca', 'kanefield', 'shugerman', 'strategised', 'reznikova', 'liptovsky', 'hradok', 'patheon', 'highertwitter', 'nyag', 'unremedied', 'molepost', 'solanezumab', 'pmis', 'believehigh', 'grexit', 'broemer', 'reince', 'affo', 'puigdemont', 'trumpism', 'sportsafe', 'redtech', 'ursano', '16bn', 'warmbrodt', '204k', 'esformes', '//bit.ly/2g2gjer', 'toigo', 'n.r.a', 'valvuloplasty', 'u.s.m.c.a', 'wrongi', 'klepin', 'unsafe.2', 'you.3', 'worldchecking', 'amzn', 'tdjc', 'lockmaker', 'timesour', 'pinebridge', 'valuationsdiageo', 'themchinese', 'solarfun', 'curveglobal', '5.5bn', 'margina', 'governmetn', 'tmunity', 'pr+', 'hospitalinspections.org', '//nyti.ms/un4oy7', 'geltzeiler', 'bloomgren', 'nicolás', 'okuwobi', 'riskscore', 'cnp.ax', 'numberedat', 'premorbid', 'porchia', 'nifla', 'overprescribe', 'espriet', 'irmat', 'optum', 'rr.l', 'mfglobal', 'cadburys', 'earliestthough', 'verlinvest', 'mulacek', 'kotagal', 'schrder', 'perritano', 'flesvig', 'argumentsindeed', 'nymann', '7.2bn', 'cuccinellis', 'c.i.a', 'lipus', 'vapers', 'akorn', 'putcha', 'sier', 'ultrastrong', 'kitakura', 'hntes', 'wechat', 'wateringly', 'skylanders', 'entegra', 'nn25160928', 'prough', 'inzitari', 'yarros', 'charanpreet', 'dabhia', 'cellseven', 'licencethen', 'darwinistic', 'infinera', 'espp', '17bn', 'whaled', 'farkouh', 'restuccia', 'deconditioned', 'manouch', 'moshayedi', 'phylopatric', 'l.p', 'altarum', 'yieldco', 'gilvarry', 'docmorris', 'i.n.f', 'spokeo', 'retweeted', 'wasendorf', 'keytruda', 'odendahl', 's.k', 'saysthat', 'malvertising', 'camcorp', 'medpage', 'ahier', 'generalisable', 'discussant', 'ticc', 'bhp.ax', 'rio.l', 'makuch', 'marketmakers', 'kolfage', 'hruksa', 'overpromises', 'unspared', 'douda', 'spikily', 'egert', 'poloz', 'bolsonaro', 'ungallant', 'a.c.a', '7,042', 'litonjua', 'kondik', 'arshamian', 'p.r', 'lumentum', 'vcsels', 'rohret', 'capitala', 'amcap', 'emanuels', 'resolutionsmeaning', 'levelshave', 'semaya', 'healthtour', 't1c', 'vipshop', 'betterof', 'alreadyyou', 'cirmo', 'epidiolex', 'dravet', '//bit.ly/1aztge5', 'asnider', 'wyen', 'himselfwell', 'educatedthe', 'jbarro', 'trauttenberg', 'moonshoti', 'mmscf', 'lobley', 'point72', 'cakeshop', '139.49', 'juurlink', 'qualifyand', 'mnn', 'gerspach', 'atypia', 'sefl', '55bn', '69bn', '14bn', 'rednecky', 'iiea', 'phenotyping', 'tijirit', 'preyss', '-and', 'plco', '2618', 'rebastinib', '3014', 'andhe', 'whatyou', 'thespecialist', 'takenplace', 'assistantsfollows', '//dmreg.co/1nljgwo', 'saikawa', 'inflam', 'workvery', 'anothervendor', 'trns', 'knighthead', 'rgy', 'obfr', 'enlightnment', 'doubleline', 'e.u', 'vidscription', 'ycmnet', 'yoshikami', 'mitigo', 'ap7', 'ca125', 'acquiror', 'nayda', 'pancioli', 'fischell', 'pcmh', 'leoning', 'threatsnixons', 'allegationseven', 'avoidably', 'obozo', 'blizzardy', 'entrec', 'treatmenteven', 'likelywould', 'weensure', 'oversimplifyingthe', 'thecataract', 'distanceor', 'matons', 'cithian', 'meiburg', 'ing.as', 'mdbi.mi', 'simps', 'flotus', 'stabbe', 'efsm', 'superinfection', 'sedgh', 'laclair', 'design\\xaded', 'rel\\xadeased', 'an\\xadnoying', 'bec\\xadause', 'lyxor', 'profitslindsay', 'jrgen', 'microgrid', 'vitalmedix', 'dexcom', 'missika', 'i.d.c', 'stefin', 'sherbin', 'd.h.s', 'serper', 'timbouctou', 'distributory', 'antiatherogenic', 'marinuzzi', 'expiredmeaning', 'e004', 'emmanouilidis', 'devincow', 'doomsters', 'bowone', 'lowflationary', '456,789', 'witlessly', '65bn', 'pricings', 't.n', 'dtegn', 'interspersal', 'nadella', 'ibrutinib', 'attackonly', 'hollyfrontier', '59,480', 'peña', 'deprescribe', 'tradereporter', '542.04', 'goitein', 'iome', 'vissers', 'nppc', 'tanona', 'morbidities', 'biamonte', 'rmds', 'ellmers', 'airfarewatchdog.com', 'excisional', 'cryptocurrency', 'coincheck', 'cataltepe', 'biomarin', '2x1012', '6,862', '72,000,000', 'bac.n', 'c.n', 'flowback', 'vbp', 'bisaro', 'hollak', 'leadiant', 'prevenion', 'newsnew', 'sederer', 'medicareon', \"a'flappin\", 'wesee', 'november1', '34,517,250', 'skierka', 'scavino', 'kobre', 'goate', 'younkin', 'vengroff', 'answersis', 'lbbb', '28bn', 'weekwant', 'steidley', 'gonzález', '58bn', 'protégés', 'marsupialization', 'trutina', 'delreal', 'aideven', 'leronlimab', '2b/3', 'cd02', 'pcatest', 'hemauer', 'savolitinib', '.a', 'maoa', '//nyti.ms/r341fq', 's.d.f', 'luthman', 'liontrust', 'emph', 'trumponomics', 'dismuke', 'a.d.a', 'e.e.o.c', 'cassivi', 'insurancenot', 'ice.n', 'intrapartum', 'shiarly', 'stld.o', 'rs.n', 'hepatologist', 'gracas', 'heran', 'gphin', 'tedprize', 'faltersremember', 'tmfdeej', 'gothamist', 'kashoggi', 'reguire', 'cringeworthy', 'underwhelm', 'flavanol', 'donationsthis', 'nccn', 'mcaleenan', 'coalitionperhaps', 'springloaded', '35:34', 'reluctances', 'orexo', 'ltip', 'indexiq', 'overexert', '//wapo.st/2rn6mel', 'leftciti', 'lagorio', 'sedran', 'gevo', 'tarnef', 'atiqi', 'grandparental', 'trembowicz', 'wyderko', 'botheration', 'creuzfeldt', 'bauler', 'mainfirst', 'soleoutcome', 'whenall', 'anecklace', 'thebest', 'ourchest', 'feedingtube', 'regionrussia', 'itone', '4.346', '4.740', 'corpbanca', 'oxybate', '12bn', '9bn', 'forward‐looking', '+2349051208634when', 'srouji', 'pehub', 'corbat', 'corrollary', 'casamassimo', 'lnder', 'r.d.t', 'answershow', 'nondevelopmental', 'glitazones', 'hyperinfection', 'banaei', 'kartsotis', 'rerunor', 'sherzan', 'ezechiel', 'copic', 'bcma', 'haughom', '2000including', 'oklahomathe', 'sivignon', 'bdsi', 'detasseling', 'cornpicking', 'judgy', '//on.wsj.com/2et8ace', 'meetingwithout', 'evidencethat', 'dumain', 'kapla', 'frideres', 'ossoff', 'a.d.h.d', 'contentthis', '.dr', 'romneyworld', 'bbby', 'a.f.l.', 'c.i.o', '567.8', 'partcipate', 'evalulation', 'nematicides', 'sowhile', 'plansout', 'orderto', 'furthermarket', 'lesscompetition', 'thelegislation', 'propafenone', 'sotalol', 'e.p.a', 'dotard', 'avanir', 'nuedexta', '7751.t', '7733.t', '8035.t', '8036.t', 'exercycle', 'linewhile', 'shitstains', 'nonrenewal', 'somebodyie', 'avav', 'nsm.n', 'lukashevich', 'oosterveld', 'rbs.l', 'awfulizing', 'janumet', 'dixhouse', '545.50', 'ingel', 'hb56', 'kwarteng', 'tv+', 'nflx', 'medcity', 'traister', 'redocument', '1.4bn', 'chondrocyte', 'loncon', 'aquadvantage', 'glennbeck.com', 'gbtv', 'douchiness', 'policywise', 'friedmen', 'ferreyr', 'flexitime', '//nyti.ms/1btmlqu', '//bit.ly/1wjecrl', 'shaub', '.the', 'posthurricane', 'prehurricane', 'volunteersafter', 'clavulanate', 'piperacillin', 'tazobactam', 'zosyn', 'bagios', 'wapo', 'snowblue', 'attachedmentsi', '.i', 'nebank', 'saczynski', 'crosstabs', 'aa+', 'neratinib', 'maelstroms', 'stan.l', 'nongroup', 'netback', 'ncib', 'misattuned', 'ctbs', 'erbb1', 'capecitabine', 'urdan', 'unsubsidised', '11,770', '47,080', 'plassat', 'turnround', '2.45bn', 'rebok', 'beicker', 'senatewhich', 'pressit', 'jcpoa', 'boustani', 'peterschmitt', 'guessous', 'mediawatch', 'biegelsen', 'dbkgn', 'jiankui', 'bsps', 'pzena', 'sisolak', 'unblinded', 'olypmic', 'nonconvertible', 'pelosis', '22bn', 'rb51', 'gipsa', 'uromedica', 'dupilumab', 'telogen', 'effluvium', 'totalis', 'sotu', 'nellen', 'peginesatide', 'derrough', 'polle', 'baltensperger', 'chondroplasty', 'convo', 'salveson', 'op.i', 'ccdoe', 'senblumenthal', 'nflcommish', 'rucaparib', 'watergoing', 'dabby', 'pfass', '•olden', '°', 'deppression', 'kalanick', 'nonpharmacological', 'nonallergic', 'galuccio', 'toweljune', 'knowmr', 'trenowden', 'portyghee', 'shulkin', 'nevertrumpers', 'giegold', 'ablations', 'matousek', 'shawkut', 'factualwhat', 'injectioncannot', '32,898', 'i.r.s', 'takethe', 'rylee', 'coene', 'guaidó', 'benisek', 'prwora', 'cimzia', 'singiser', 'mor208', '18,378', 'concernedthe', 'partiespaused', 'cellectis', 'eargo', 'slavitt', 'cimziaâ', '®', 'triangulator', 'mnsure', 'gablofen', 'olness', 'marette', 'swetnick', 'pnk', 'crème', 'brûlée', 'behsudi', 'zacary', 'techeven', 'tromps', 'huttenhower', '79mr', 'takushi', 'ishikura', 'aledade', 'mostashari', 'costscosts', '.topx', 'enestro', 'parsortix', 'eskesen', 'azpia', 'ibla.mc', 'f.n', 'economicsit', 'sweatily', 'dkr53bn', '8.3bn', 'czapp', 'drrich', 'manchik', 'seriousconsequences', 'abbvie', 'bondholdings', 'costerg', 'cyence', '7.5bn', 'h.s.a', 'kalobios', 'brainlessly', 'reify', 'oookaay', 'chatbots', 'ameringen', 'csalp', 'ttip', 'realdonaldtrump', 'undisbursed', 'playbookers', 'mutualization', 'bouhara', 'foroud', '//bit.ly/pdyenx', 'foolfest', 'toomeys', 'fsoc', 'kolhmann', 'sp+', 'paymentsnot', 'guglielmotti', 'mmt.if', 'multigenic', 'nidawi', 'o.n.d.c.p', 'wergin', 'minusma', 'pfe.n', 'swedo', 'lozman', 'putinwho', 'poehling', '9,580', '12,902', 'otherhand', 'ecigarettes', '1trn', 'luschini', 'preteenagers', 'dal.n', 'nwa.n', 'famewave', 'albence', 'toldme', 'whatthey', 'thatonly', 'orher', 'forcompetence', 'ipaa', 'ungari', 'sageen', 'beaverness', 'runkeeper', '143.70', 'kalir', 'heartwire', 'hernández', 'avocadoes', 'garzotto', 'youdid', 'iley', 'umich', 'biggish', 'unrevoked', 'kohane', 'prewarned', 'rutqvist', 'coinbase', 'ehrsam', 'blockchain', 'tomdispatch', '20.3bn', '2.9bn', 'financialisation', 'housingthe', 'measured.2', 'interest.3', 'outcome.4', 'redicting', '//bit.ly/1khnaui', 'cemma', 'caitlinzemma', '346bn', 'washeteria', 'ishrak', 'hoogendyk', 'adheretech', 'abruptlyas', 'truty', 'withthemselves', 'andstrike', 'leiomyosarcomas', \"woulnd't\", 'sederberg', '2650bc', 'edro', 'gloviczki', 'jived', '5thbday', 'obamacarethe', 'democratsthat', 'krzanich', 'weightsit', 'seasonand', 'scailex', 'scix.ta', 'linora', 'consonery', 'brexiteers', 'hypertriglyceridemic', 'sequencingin', 'stefanek', 'cordovilla', 'mandrola', '6,584', 'chrystia', '聳', '25:44', '45and', 'boeckler', 'npdb', 'glausser', 'ricol', '35/31', 'ovitt', 'cpri', 'aqlan', '9202.t', 'qan.ax', 'ai.ul', 'h.w', 'epocrates', 'drummy', 'schnatter', 'hawkinberry', 'shuanghui', 'josé', 'polkes', 'untether', 'interstim', 'liposuctioned', 'cirka', 'horsager', \"yar'adua\", 'vsoe', 'cisgendered', 'zoetis', 'nonproven', 'schlapp', 'posess', 'razaqzada', 'spanberger', 'inspra', 'elseplease', 'tothem', 'becausei', 'nechelput', 'esvelt', 'presidentgreens', 'forthare', 'he/', 'restasis', 'intromission', 'dodick', 'ngdp', 'lnkd.dl', 'panl', 'lubitz', 'skinactivist', '300bn', 'wandoan', '200bn', '3g.', 'bokkelen', 'thinkfor', 'thefinancial', 'tohim', 'fragmentedsystem', 'systemwould', 'treattheir', 'changethe', 'cispa', 'morethe', 'tmall', 'micrometastases', 'jumbomatic', 'dourson', 'dealbut', 'birtel', 'deplorables', 'weightsif', 'c.w', 'balwani', '1.2bn', 'suahasil', 'nazara', 'zanny', 'flatto', 'culpritboth', 'unobligated', 'vilnerable', 'psychoanalyzing', 'ftfm', 'smartwatch', 'sabbs', 'coratti', 'omfif', \"l'oréal\", 'nawana', 'afib', 'acase', 'surgeonleft', 'publicityconcerning', 'iwatch', 'proco', 'bnb.ax', 'aep.ax', 'zarzeczny', 'giventhough', 'hafle', 'demétrio', 'postuma', 'jannetta', 'chemed', 'glendevon', 'hampshirenew', 'nieca', 'abinbev', 'bakish', '15,302', '3.30am', '50u/1', '25u/0.5', 'symc', '13bn', '60bn', '100bn', 'preventedif', 'triatomine', 'broadridge', 'advicewhile', 'hodis', 'tabachnick', 'overcapitalized', 'insoll', 'fidessa', 'q1/2019', 'netbacks', '/us', 'sfr210', 'hummler', 'perfectionistic', 'progressivetokyo', 'bruera', '267,700', 'moscillo', 'effectuating', 'camuñez', 'michiro', '7203.t', '7201.t', '1.6tn', 'pão', 'açúcar', 'nesterczuk', '2891.tw', 'rttgers', 'estis', 'dinamit', 'giuricin', 'sinofert', 'agraz', 'storiesweighing', 'f.a.a', 'cryptocurrencies', 'schmidle', 'cyberberkut', 'daign', 'ccilia', 'denverton', 'whohas', 'medicalert', 'abracelet', 'aboutthe', 'beallergic', 'diseasethat', 'factthat', 'diagnosedproperly', 'thyroidcancer', 'ryleigh', 'speechthere', 'answerscochlear', 'westerbeck', 'resect', 'roguishly', 'iex', 'nazarali', 'midwests', 'securequity', 'axovant', 'nelotanserin', 'roivant', 'kirschman', 'stormchaser', 'o.g.e', 'evofem', 'ocare', 'mot.n', 'xeljanz', 'entyvio', 'arbitraged', 'cgus', 'tilray', 'lixivaptan', 'tlantic', 'atvi.o', 'viv.pa', 'schoenebaum', 'invensense', 'dri.n', 'outsideif', 'jiade', 'unipec', 'pericardiectomy', 'conibear', 'superscary', 'shulyatyeva', 'ceptaris', 'sadredin', 'coriell', 'terez', 'prismsport', 'worldvista', 'troughing', 'exfiltrated', '//bit.ly/1losuxk', 'badasses', 'mobihealthnews', 'kienitz', 'rebleed', 'presstime', 'ivd', 'bernik', 'mandateand', 'doesmr', 'andridge', 'eiopa', 'alphazero', 'schriock', 'tipirneni', 'ucits', '350.org', 'ex\\xadposed', 'oathbreaking', 'fxj.ax', \"o'chee\", 'victrex', 'alll', 'inadvisably', 'upselling', 'emoji', 'zydelig', 'pillpack', 'outwhich', 'unlikelya', '1.7bn', 'lebrikizumab', 'leaviss', 'silvinit', 'rpe65', 'percher', 'wanggaard', '13,919', '//bit.ly/2gjfsae', 'fuct', 'burkhauser', '0.1854', 'olivetree', 'lbhi', 'muirhouse', 'anonymizing', 'reidentified', 'answerscataract', 'jarlov', 'hollowdweller', 'schonlein', '//www.toyotaofdecatur.com', '2.2bn', 'overprotecting', 'urpilainen', 'skarich', 'fdasia', 'hojat', 'tornier', 't.p.p', 'supercommittee', 'termfiscal', '129:1815', 'ratpac', 'watchespn', 'faubion', 'landver', 'iscaro', 'landcolt', 'housea', 'choppering', 'jpm.n', 'malvey', '//bit.ly/1jznvnf', 'metrokin', 'a.s.c.o', 'quirónsalud', 'pethokoukis', 'no.1', 'd.c.i.s', 'sicherer', 'waterminder', 'splunk', 'rangasamy', '409.12', 'qga', 'missier', 'ioer', 'gaffed', 'vege', '32bn']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yAN7rJ7YiN99","colab_type":"code","colab":{}},"source":["corpus_words = []\n","for element in corpus:\n","  for sent in element['args']:\n","    for word in sent:\n","      if word not in not_in:\n","        if word not in corpus_words:\n","          corpus_words.append(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNSW1cqFhf_-","colab_type":"code","colab":{}},"source":["seed = 2048"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeK_vo9yjKQX","colab_type":"code","colab":{}},"source":["mapping = []\n","custom_mapping = {0 : 0}\n","idx = 1\n","for w in corpus_words:\n","  mapping.append(w2v[w2i[w]])\n","  custom_mapping[w] = idx\n","  idx+=1\n","\n","pad = [0]*300\n","mapping.insert(0,pad)\n","\n","mapping = np.array(mapping)\n","\n","np.random.seed(seed)\n","\n","for i in range(len(not_in)):\n","  rnd = np.array([np.random.uniform(-1,1,300)])\n","  mapping = np.append(mapping,rnd,axis = 0)\n","  custom_mapping[not_in[i]] = idx\n","  idx+=1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IchsZgsUDq7j","colab_type":"code","colab":{}},"source":["import pickle\n","\n","with open(\"custom_mapping.pickle\",'wb') as f:\n","  pickle.dump(custom_mapping, f)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GWh9jCGGrFZU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2c951d4f-242a-4f5d-e174-e8a2660f5203","executionInfo":{"status":"ok","timestamp":1581364578004,"user_tz":-330,"elapsed":5129,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}}},"source":["mapping.shape"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(24411, 300)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"IveYvoItpz5h","colab_type":"code","outputId":"6b380c10-d8df-48b6-d5b9-d3def816758b","executionInfo":{"status":"ok","timestamp":1581245392615,"user_tz":-330,"elapsed":2523,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["type(mapping[0])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"VpSiph_13ddN","colab_type":"code","outputId":"b2f9d50d-c7e1-4194-ada9-547cb6bc2800","executionInfo":{"status":"ok","timestamp":1581244679569,"user_tz":-330,"elapsed":1429,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(mapping) == len(corpus_words) + len(not_in) + 1"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"dVvXmAtd50qN","colab_type":"code","colab":{}},"source":["max_len = 0\n","this = 0\n","for e in corpus:\n","  for x in e['args']:\n","    if len(x)>max_len:\n","      max_len = len(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BML8dIwBh3rb","colab_type":"code","outputId":"c1b96cc7-ed21-4674-e148-8542c439d301","executionInfo":{"status":"ok","timestamp":1581362241994,"user_tz":-330,"elapsed":61,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max_len"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["62"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"8poCqj38juE_","colab_type":"code","colab":{}},"source":["import pickle\n","import torch.autograd as autograd\n","import torch\n","\n","tweet_200_da_embedding_seqs=[]\n","data_label = []\n","for tweet in corpus:\n","    tweet_200_word_embedding_seqs=[]\n","    for da in tweet['args']:\n","        tweet_200_word_embedding_seqs.append([autograd.Variable(torch.FloatTensor(mapping[custom_mapping[word]])) for word in da])\n","    tweet_200_da_embedding_seqs.append(tweet_200_word_embedding_seqs)\n","    data_label.append(int(tweet['label']))\n","\n","pickle.dump(tweet_200_da_embedding_seqs, open(\"data/causal_explanation_200_da_embedding_seqs_\"+\"glove\"+\".list\", \"wb\"))\n","pickle.dump(data_label, open(\"data/bilstm_label.list\",\"wb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2oqHuZNrw4M0","colab_type":"code","colab":{}},"source":["pickle.dump(mapping,open(\"data/mapping_bilstm.list\", \"wb\"))\n","pickle.dump(custom_mapping,open( \"data/custom_mapping_bilstm.list\",\"wb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9AGgJg4kAOo","colab_type":"code","colab":{}},"source":["import pickle\n","import numpy as np\n","import torch.autograd as autograd\n","import torch\n","\n","tweet_200_da_embedding_seqs = pickle.load(open(\"data/causal_explanation_200_da_embedding_seqs_\"+\"glove\"+\".list\", \"rb\"))\n","data_label = pickle.load(open(\"data/bilstm_label.list\",\"rb\"))\n","mapping = pickle.load(open(\"data/mapping_bilstm.list\", \"rb\"))\n","custom_mapping = pickle.load(open( \"data/custom_mapping_bilstm.list\",\"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sB-4wure7YBA","colab_type":"code","colab":{}},"source":["from torch.utils.data.sampler import SubsetRandomSampler\n","from sklearn.model_selection import train_test_split\n","\n","split = 0.2\n","indices = np.arange(len(tweet_200_da_embedding_seqs))\n","splits = train_test_split(indices, test_size = split, random_state = seed, stratify = data_label)\n","\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","\n","train_sampler = SubsetRandomSampler(splits[0])\n","valid_sampler = SubsetRandomSampler(splits[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILv7FG8SCCNo","colab_type":"code","colab":{}},"source":["class text_dataset(torch.utils.data.Dataset):\n","    \n","    def __init__(self, data, label):\n","        self.data = data\n","        self.labels = label\n","\n","        \n","    def __len__(self):\n","        return len(self.labels)\n","        \n","    def __getitem__(self, idx):\n","\n","        l = self.labels[idx]\n","        # print(self.data[idx])\n","        sentence = self.data[idx]\n","\n","        return sentence, l"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I_ZibGLtVcHf","colab_type":"code","colab":{}},"source":["import torch\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import csv\n","import pickle\n","import sys\n","import numpy as np\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import confusion_matrix\n","\n","\n","class BiLSTM_Causal_Explanation_Identification(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, is_cuda, causality_num_layer=1,causality_num_direction=1):\n","        super(BiLSTM_Causal_Explanation_Identification, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.causality_num_layer = causality_num_layer\n","        self.causality_num_direction = causality_num_direction\n","        self.is_cuda=is_cuda\n","        self.du_lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True) # Word LSTM on the paper\n","        self.causality_lstm = nn.LSTM(hidden_dim * 2, hidden_dim, bidirectional=causality_num_direction == 2) # DA LSTM on the paper\n","\n","        self.hidden_to_causality = nn.Linear(hidden_dim * causality_num_direction, 2)\n","\n","        if is_cuda:\n","            self.du_lstm = self.du_lstm.cuda()\n","            self.causality_lstm = self.causality_lstm.cuda()\n","            self.hidden_to_causality = self.hidden_to_causality.cuda()\n","\n","    def init_du_hidden(self):\n","        if self.is_cuda:\n","            return (autograd.Variable(torch.zeros(2, 1, self.hidden_dim)).cuda(),autograd.Variable(torch.zeros(2, 1, self.hidden_dim)).cuda())\n","        else:\n","            return (autograd.Variable(torch.zeros(2, 1, self.hidden_dim)),autograd.Variable(torch.zeros(2, 1, self.hidden_dim)))\n","\n","    def init_classifier_hidden(self):\n","        if self.is_cuda:\n","            return (autograd.Variable(torch.zeros(self.causality_num_layer * self.causality_num_direction, 1, self.hidden_dim)).cuda(),autograd.Variable(torch.zeros(self.causality_num_layer * self.causality_num_direction, 1, self.hidden_dim)).cuda())\n","        else:\n","            return (autograd.Variable(torch.zeros(self.causality_num_layer * self.causality_num_direction, 1, self.hidden_dim)),autograd.Variable(torch.zeros(self.causality_num_layer * self.causality_num_direction, 1, self.hidden_dim)))\n","\n","    def forward(self, du_embedding_seq):\n","        # print(len(du_embedding_seq))\n","        # use batch input and get all the hidden vectors and concatenate them\n","        tweet_input = []\n","        # keep track of missing dus and average all embeddings of dus \n","        empty_seq_du_idxs=[]\n","        for i in range(len(du_embedding_seq)):\n","            # get du embeddings from the given tweet\n","            # print(word_embedding_seq)\n","            word_embedding_seq = du_embedding_seq[i]\n","            if len(word_embedding_seq)==0:\n","                empty_seq_du_idxs.append(i)\n","                continue\n","            word_embedding_seq = torch.cat(word_embedding_seq).view(len(word_embedding_seq), 1, -1)\n","            if self.is_cuda:\n","                word_embedding_seq = word_embedding_seq.cuda()\n","\n","            du_output, (du_hidden, du_cell_state) = self.du_lstm(word_embedding_seq, self.init_du_hidden())\n","            tweet_input.append(du_hidden.view(self.hidden_dim*2, 1, -1))\n","\n","        tweet_input=list(tweet_input)\n","        tweet_input_mean = torch.stack(tweet_input).mean(dim=0)\n","\n","        for i in range(len(empty_seq_du_idxs)):\n","            print(\"empty?\")\n","            tweet_input.insert(i+empty_seq_du_idxs[i], tweet_input_mean)\n","\n","        tweet_input = torch.cat(tweet_input).view(len(tweet_input), 1,-1)  # concat hidden vectors from the last cells of forward and backward LSTM\n","        tweet_input = F.dropout(tweet_input, p=0.3, training=self.training)\n","        tweet_output, (tweet_hidden, tweet_cell_state) = self.causality_lstm(tweet_input, self.init_classifier_hidden())\n","        # print(tweet_output.size())\n","        shape = tweet_output.size()\n","        tweet_output = tweet_output.view(shape[1], shape[0], shape[2])\n","        # print(tweet_output.size())\n","        causality_vec = self.hidden_to_causality(tweet_output.view(len(du_embedding_seq), -1))\n","        # print(causality_vec.size())\n","        causality_score = F.log_softmax(causality_vec,dim=1)\n","        return torch.sum(causality_score, dim = 0).unsqueeze(0)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-u3w-JkSoBV","colab_type":"code","outputId":"911bbd1e-4e84-4e8b-9e61-5013198bd3bd","executionInfo":{"status":"ok","timestamp":1581413497022,"user_tz":-330,"elapsed":1062,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}},"colab":{"base_uri":"https://localhost:8080/","height":106}},"source":["import torch\n","import torch.autograd as autograd\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import csv\n","import pickle\n","import sys\n","import numpy as np\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","import argparse\n","import time\n","import math\n","# from BiLSTM_Causal_Explanation_Identification import BiLSTM_Causal_Explanation_Identification\n","\n","\n","def time_since(start):\n","    now = time.time()\n","    s = now - start\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","parser = argparse.ArgumentParser(description='BiLSTM_Causal_Explanation_Identificatio_Training')\n","# def main():\n","\n","parser.add_argument('--word_dim', type=int, default=300, help='the dimension of the word embedding to be used. Default=25')\n","parser.add_argument('--hidden_dim', type=int, default=100, help='the dimension of the hidden layer to be used. Default=25')\n","parser.add_argument('--seed', type=int, default=seed, help='random seed to use. Default=1')\n","parser.add_argument('--nEpochs', type=int, default=50, help='number of epochs to train for')\n","parser.add_argument('--batch_size', type=int, default=1, help='batch size')\n","parser.add_argument('--lr', type=float, default=0.01, help='Learning Rate. Default=0.01')\n","parser.add_argument('--cuda', default=True, help='use cuda?')\n","parser.add_argument('--grad', type=str, default='SGD', help='Optimzer type: SGD? Adam? Default=SGD')\n","parser.add_argument('--train_shuffle', type=str, default='yes',\n","                    help='Shuffle the dataset for each epoch? no/shuffle/replace')\n","parser.add_argument('--model_path', type=str, default='./Trained_Models/',\n","                    help='the path for saving intermediate models')\n","parser.add_argument('--train_data', type=str, default='./preprocessed_embeddings/',\n","                    help='the path of word embedding seqs for training')\n","parser.add_argument('--train_labels', type=str, default='./preprocessed_embeddings/',\n","                    help='the path of label vectors for training')\n","parser.add_argument('--valid_data', type=str, default='./preprocessed_embeddings/',\n","                    help='the path of word embedding seqs for validation')\n","parser.add_argument('--valid_labels', type=str, default='./preprocessed_embeddings/',\n","                    help='the path of label vectors for validation')\n","parser.add_argument('--causality_num_direction', type=int, default=2,\n","                    help='# of direction of RNN for causality detection, Default=2 (bidirectional)')\n","\n","opt = parser.parse_args([])\n","print(opt)\n","word_embedding_dim=opt.word_dim\n","hidden_dim=opt.hidden_dim\n","learning_rate=opt.lr\n","optimizer_type=opt.grad\n","c_num=opt.causality_num_direction\n","\n","\n","\n","is_cuda= opt.cuda\n","model_name=\"CE_\"+str(word_embedding_dim)+'_'+str(hidden_dim)+'_lr'+str(learning_rate).replace('.','_')+'_'+optimizer_type+'_'\n","torch.manual_seed(opt.seed)\n","if is_cuda:\n","    torch.cuda.manual_seed(opt.seed)\n","\n","data = tweet_200_da_embedding_seqs\n","dataset = text_dataset(data, data_label)\n","train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=opt.batch_size,\n","                                           sampler = train_sampler)\n","val_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=opt.batch_size,\n","                                           sampler = valid_sampler)\n","\n","# word embedding pickle\n","# train_word_embed_seqs = pickle.load(open(opt.train_data, \"rb\"))\n","# valid_word_embed_seqs = pickle.load(open(opt.valid_data, \"rb\"))\n","training_set_size=len(data)*(1-split)\n","valid_set_size=len(data)*(split)\n","print(\"Training Set Size:\",training_set_size)\n","print(\"Validation Set Size:\",valid_set_size)\n","# tweet da pickle\n","# causality gs pickle\n","# ce_train_label_vecs = pickle.load(open(opt.train_labels,\"rb\"))\n","# ce_train_labels = [int(ce) for ce_train_label_vec in ce_train_label_vecs for ce in ce_train_label_vec]\n","# ce_valid_label_vecs = pickle.load(open(opt.valid_labels,\"rb\"))\n","# ce_valid_labels = [int(ce) for ce_valid_label_vec in ce_valid_label_vecs for ce in ce_valid_label_vec]\n","\n","model = BiLSTM_Causal_Explanation_Identification(word_embedding_dim, hidden_dim, is_cuda, causality_num_direction=c_num)\n","loss_function = nn.NLLLoss()\n","\n","if optimizer_type=='SGD':\n","    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","else:\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","if is_cuda:\n","    print(\"On Cuda\")\n","    model = model.cuda()\n","    loss_function = loss_function.cuda()\n","    # ce_train_label_vecs=[ce_train_label_vec.cuda() for ce_train_label_vec in ce_train_label_vecs]\n","    # ce_valid_label_vecs=[ce_valid_label_vec.cuda() for ce_valid_label_vec in ce_valid_label_vecs]\n","\n","\n","\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Namespace(batch_size=1, causality_num_direction=2, cuda=True, grad='SGD', hidden_dim=100, lr=0.01, model_path='./Trained_Models/', nEpochs=50, seed=2048, train_data='./preprocessed_embeddings/', train_labels='./preprocessed_embeddings/', train_shuffle='yes', valid_data='./preprocessed_embeddings/', valid_labels='./preprocessed_embeddings/', word_dim=300)\n","Training Set Size: 10400.0\n","Validation Set Size: 2600.0\n","On Cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"007df3a5-270b-4f79-e0b2-f20965f4061f","id":"-m33dmOXXCvU","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1581416625523,"user_tz":-330,"elapsed":3127149,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}}},"source":["best_weighted_f1=0.80 # preliminary best f1\n","total_start=time.time()\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","\n","for epoch in range(1,opt.nEpochs+1):\n","    epoch_start=time.time()\n","    model.train()\n","    losses=0\n","    # if opt.train_shuffle=='replace':\n","    #     training_set=np.random.choice(training_set_size,training_set_size,replace=True)\n","    # elif opt.train_shuffle=='shuffle':\n","    #     training_set=np.random.choice(training_set_size,training_set_size,replace=False)\n","    # else:\n","    #     training_set=range(training_set_size)\n","    \n","    for feature, label in train_loader:\n","\n","        if is_cuda:\n","          label = label.cuda()\n","    # for i in training_set:\n","        model.zero_grad()\n","        causality_score = model(feature)\n","        # print(causality_score.size())\n","        # print(label.size())\n","        loss = loss_function(causality_score, label)\n","        loss.backward()\n","        optimizer.step()\n","        losses+=float(loss)\n","\n","    end_time=time_since(epoch_start)\n","    total_time=time_since(total_start)\n","    print(\"Epoch #: \" + str(epoch))\n","    print(\"Training Loss: \" + str(losses))\n","    print(\"Epoch Time: %s\"%(end_time))\n","\n","\n","    if epoch%1==0:\n","        model.eval()\n","        predictions=[]\n","        valid_losses = 0\n","        labels = None\n","        c = 0\n","        for feature, label in val_loader:\n","            if is_cuda:\n","              label = label.cuda()\n","        # for i in range(valid_set_size):\n","            causality_score=model(feature)\n","            _,prediction=causality_score.max(1)\n","            [predictions.append(int(int_label)) for int_label in prediction]\n","            valid_loss = loss_function(causality_score, label)\n","            valid_losses += float(valid_loss)\n","            if c==0:\n","              c+=1\n","              labels = label.cpu().numpy().flatten()\n","            else:\n","              labels = np.concatenate((labels, label.cpu().numpy().flatten()))\n","\n","        precision, recall, f1, support = precision_recall_fscore_support(labels, predictions)\n","        weighted_precision, weighted_recall, weighted_f1, weighted_support = precision_recall_fscore_support(labels, predictions, average='weighted')\n","\n","\n","        if weighted_f1>best_weighted_f1:\n","\n","            best_weighted_f1=weighted_f1\n","            print(\"The bset F1 upto this point: \" + str(weighted_f1))\n","            # torch.save(model.state_dict(),opt.model_path + model_name + \"dir_\" + str(c_num) + \"_f1_\" + str(weighted_f1)[:7] + '_epoch_' + str(epoch) + '_Dropout_0_3' + \"_early_stop_saved.ptstdict\")\n","\n","\n","\n","        print(\"[Results at epoch #: \"+str(epoch)+\"]\")\n","        print(\"F1: \"+str(f1))\n","        print(\"Weighted F1: \" + str(weighted_f1))\n","        print(\"Precision: \" + str(precision))\n","        print(\"Recall: \" + str(recall))\n","        print(\"Confusion Matrix (Label \\\\ Prediction)\")\n","        print(confusion_matrix(labels, predictions))\n","        print(\"Loss: \" + str(losses))\n","        print(\"Validation Loss: \" + str(valid_losses))\n","        print(\"Epoch Time: %s\"%(end_time))\n","        print(\"Total Time: %s\"%(total_time))\n","        print()\n","        print(\"Test F1-score in epoch %d is %.3f\" % (epoch, f1_score(labels,predictions)))\n","        print()\n","\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch #: 1\n","Training Loss: 11398.355905264616\n","Epoch Time: 1m 26s\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["The bset F1 upto this point: 0.8354327216885783\n","[Results at epoch #: 1]\n","F1: [0.94072112 0.        ]\n","Weighted F1: 0.8354327216885783\n","Precision: [0.88807692 0.        ]\n","Recall: [1. 0.]\n","Confusion Matrix (Label \\ Prediction)\n","[[2309    0]\n"," [ 291    0]]\n","Loss: 11398.355905264616\n","Validation Loss: 2660.8581885695457\n","Epoch Time: 1m 26s\n","Total Time: 1m 26s\n","\n","Test F1-score in epoch 1 is 0.000\n","\n","Epoch #: 2\n","Training Loss: 10534.330721735954\n","Epoch Time: 1m 27s\n","The bset F1 upto this point: 0.8376293711047945\n","[Results at epoch #: 2]\n","F1: [0.94064858 0.02020202]\n","Weighted F1: 0.8376293711047945\n","Precision: [0.88897456 0.5       ]\n","Recall: [0.99870074 0.01030928]\n","Confusion Matrix (Label \\ Prediction)\n","[[2306    3]\n"," [ 288    3]]\n","Loss: 10534.330721735954\n","Validation Loss: 2611.0603273510933\n","Epoch Time: 1m 27s\n","Total Time: 3m 4s\n","\n","Test F1-score in epoch 2 is 0.020\n","\n","Epoch #: 3\n","Training Loss: 9885.126290917397\n","Epoch Time: 1m 28s\n","The bset F1 upto this point: 0.8772471800645175\n","[Results at epoch #: 3]\n","F1: [0.94736842 0.32085561]\n","Weighted F1: 0.8772471800645175\n","Precision: [0.90822408 0.72289157]\n","Recall: [0.99003898 0.20618557]\n","Confusion Matrix (Label \\ Prediction)\n","[[2286   23]\n"," [ 231   60]]\n","Loss: 9885.126290917397\n","Validation Loss: 2125.1887725293636\n","Epoch Time: 1m 28s\n","Total Time: 4m 42s\n","\n","Test F1-score in epoch 3 is 0.321\n","\n","Epoch #: 4\n","Training Loss: 9079.311879068613\n","Epoch Time: 1m 29s\n","The bset F1 upto this point: 0.8968484233608466\n","[Results at epoch #: 4]\n","F1: [0.94335559 0.52782765]\n","Weighted F1: 0.8968484233608466\n","Precision: [0.93830334 0.55263158]\n","Recall: [0.94846254 0.50515464]\n","Confusion Matrix (Label \\ Prediction)\n","[[2190  119]\n"," [ 144  147]]\n","Loss: 9079.311879068613\n","Validation Loss: 2331.1229692697525\n","Epoch Time: 1m 29s\n","Total Time: 6m 21s\n","\n","Test F1-score in epoch 4 is 0.528\n","\n","Epoch #: 5\n","Training Loss: 8355.803257524967\n","Epoch Time: 1m 26s\n","The bset F1 upto this point: 0.905788901073912\n","[Results at epoch #: 5]\n","F1: [0.95428692 0.5209713 ]\n","Weighted F1: 0.905788901073912\n","Precision: [0.9290402  0.72839506]\n","Recall: [0.98094413 0.40549828]\n","Confusion Matrix (Label \\ Prediction)\n","[[2265   44]\n"," [ 173  118]]\n","Loss: 8355.803257524967\n","Validation Loss: 1912.282298952341\n","Epoch Time: 1m 26s\n","Total Time: 7m 57s\n","\n","Test F1-score in epoch 5 is 0.521\n","\n","Epoch #: 6\n","Training Loss: 7617.951040536165\n","Epoch Time: 1m 26s\n","The bset F1 upto this point: 0.9128778252554476\n","[Results at epoch #: 6]\n","F1: [0.95613477 0.56964657]\n","Weighted F1: 0.9128778252554476\n","Precision: [0.93609959 0.72105263]\n","Recall: [0.97704634 0.47079038]\n","Confusion Matrix (Label \\ Prediction)\n","[[2256   53]\n"," [ 154  137]]\n","Loss: 7617.951040536165\n","Validation Loss: 1868.3018973767757\n","Epoch Time: 1m 26s\n","Total Time: 9m 33s\n","\n","Test F1-score in epoch 6 is 0.570\n","\n","Epoch #: 7\n","Training Loss: 6926.659673094749\n","Epoch Time: 1m 26s\n","The bset F1 upto this point: 0.9196928987165139\n","[Results at epoch #: 7]\n","F1: [0.95796885 0.61598441]\n","Weighted F1: 0.9196928987165139\n","Precision: [0.94407065 0.71171171]\n","Recall: [0.97228237 0.54295533]\n","Confusion Matrix (Label \\ Prediction)\n","[[2245   64]\n"," [ 133  158]]\n","Loss: 6926.659673094749\n","Validation Loss: 1870.1464910805225\n","Epoch Time: 1m 26s\n","Total Time: 11m 9s\n","\n","Test F1-score in epoch 7 is 0.616\n","\n","Epoch #: 8\n","Training Loss: 6433.50151771307\n","Epoch Time: 1m 25s\n","[Results at epoch #: 8]\n","F1: [0.9570421  0.61420345]\n","Weighted F1: 0.9186705466278344\n","Precision: [0.94472574 0.69565217]\n","Recall: [0.96968385 0.54982818]\n","Confusion Matrix (Label \\ Prediction)\n","[[2239   70]\n"," [ 131  160]]\n","Loss: 6433.50151771307\n","Validation Loss: 1789.0347571074963\n","Epoch Time: 1m 25s\n","Total Time: 12m 44s\n","\n","Test F1-score in epoch 8 is 0.614\n","\n","Epoch #: 9\n","Training Loss: 5877.925303339958\n","Epoch Time: 1m 25s\n","[Results at epoch #: 9]\n","F1: [0.95914069 0.57079646]\n","Weighted F1: 0.9156760096186106\n","Precision: [0.93357934 0.80124224]\n","Recall: [0.98614119 0.44329897]\n","Confusion Matrix (Label \\ Prediction)\n","[[2277   32]\n"," [ 162  129]]\n","Loss: 5877.925303339958\n","Validation Loss: 1964.6476547122002\n","Epoch Time: 1m 25s\n","Total Time: 14m 19s\n","\n","Test F1-score in epoch 9 is 0.571\n","\n","Epoch #: 10\n","Training Loss: 5276.256549417973\n","Epoch Time: 1m 24s\n","[Results at epoch #: 10]\n","F1: [0.95466321 0.63028169]\n","Weighted F1: 0.9183574343630536\n","Precision: [0.95178648 0.64620939]\n","Recall: [0.95755738 0.61512027]\n","Confusion Matrix (Label \\ Prediction)\n","[[2211   98]\n"," [ 112  179]]\n","Loss: 5276.256549417973\n","Validation Loss: 1876.5338633358479\n","Epoch Time: 1m 24s\n","Total Time: 15m 53s\n","\n","Test F1-score in epoch 10 is 0.630\n","\n","Epoch #: 11\n","Training Loss: 4746.035357683897\n","Epoch Time: 1m 26s\n","[Results at epoch #: 11]\n","F1: [0.94958714 0.61204013]\n","Weighted F1: 0.9118078369299955\n","Precision: [0.95290013 0.59609121]\n","Recall: [0.9462971  0.62886598]\n","Confusion Matrix (Label \\ Prediction)\n","[[2185  124]\n"," [ 108  183]]\n","Loss: 4746.035357683897\n","Validation Loss: 2062.9509098529816\n","Epoch Time: 1m 26s\n","Total Time: 17m 30s\n","\n","Test F1-score in epoch 11 is 0.612\n","\n","Epoch #: 12\n","Training Loss: 3933.3944205343723\n","Epoch Time: 1m 26s\n","[Results at epoch #: 12]\n","F1: [0.95747832 0.57505285]\n","Weighted F1: 0.914676081663305\n","Precision: [0.93589744 0.74725275]\n","Recall: [0.98007796 0.46735395]\n","Confusion Matrix (Label \\ Prediction)\n","[[2263   46]\n"," [ 155  136]]\n","Loss: 3933.3944205343723\n","Validation Loss: 1972.2818262279034\n","Epoch Time: 1m 26s\n","Total Time: 19m 5s\n","\n","Test F1-score in epoch 12 is 0.575\n","\n","Epoch #: 13\n","Training Loss: 3493.0297217667103\n","Epoch Time: 1m 26s\n","[Results at epoch #: 13]\n","F1: [0.95816691 0.55079007]\n","Weighted F1: 0.912572042049291\n","Precision: [0.93096405 0.80263158]\n","Recall: [0.98700736 0.41924399]\n","Confusion Matrix (Label \\ Prediction)\n","[[2279   30]\n"," [ 169  122]]\n","Loss: 3493.0297217667103\n","Validation Loss: 2326.901051968336\n","Epoch Time: 1m 26s\n","Total Time: 20m 41s\n","\n","Test F1-score in epoch 13 is 0.551\n","\n","Epoch #: 14\n","Training Loss: 2947.3643104732037\n","Epoch Time: 1m 29s\n","[Results at epoch #: 14]\n","F1: [0.95555087 0.53421634]\n","Weighted F1: 0.9083938162515919\n","Precision: [0.93027071 0.74691358]\n","Recall: [0.9822434  0.41580756]\n","Confusion Matrix (Label \\ Prediction)\n","[[2268   41]\n"," [ 170  121]]\n","Loss: 2947.3643104732037\n","Validation Loss: 2258.213055342436\n","Epoch Time: 1m 29s\n","Total Time: 22m 21s\n","\n","Test F1-score in epoch 14 is 0.534\n","\n","Epoch #: 15\n","Training Loss: 2437.3685571551323\n","Epoch Time: 1m 27s\n","The bset F1 upto this point: 0.9265904232904489\n","[Results at epoch #: 15]\n","F1: [0.95835141 0.67457627]\n","Weighted F1: 0.9265904232904489\n","Precision: [0.96001738 0.66555184]\n","Recall: [0.95669121 0.6838488 ]\n","Confusion Matrix (Label \\ Prediction)\n","[[2209  100]\n"," [  92  199]]\n","Loss: 2437.3685571551323\n","Validation Loss: 2139.017419576645\n","Epoch Time: 1m 27s\n","Total Time: 23m 59s\n","\n","Test F1-score in epoch 15 is 0.675\n","\n","Epoch #: 16\n","Training Loss: 1981.2994467914104\n","Epoch Time: 1m 28s\n","[Results at epoch #: 16]\n","F1: [0.95672972 0.66888519]\n","Weighted F1: 0.9245132780995384\n","Precision: [0.96069869 0.6483871 ]\n","Recall: [0.95279342 0.69072165]\n","Confusion Matrix (Label \\ Prediction)\n","[[2200  109]\n"," [  90  201]]\n","Loss: 1981.2994467914104\n","Validation Loss: 2222.1262890696526\n","Epoch Time: 1m 28s\n","Total Time: 25m 37s\n","\n","Test F1-score in epoch 16 is 0.669\n","\n","Epoch #: 17\n","Training Loss: 1951.507191926241\n","Epoch Time: 1m 28s\n","[Results at epoch #: 17]\n","F1: [0.96093418 0.6244898 ]\n","Weighted F1: 0.9232782916204207\n","Precision: [0.94252395 0.76884422]\n","Recall: [0.98007796 0.5257732 ]\n","Confusion Matrix (Label \\ Prediction)\n","[[2263   46]\n"," [ 138  153]]\n","Loss: 1951.507191926241\n","Validation Loss: 2569.9004690647125\n","Epoch Time: 1m 28s\n","Total Time: 27m 15s\n","\n","Test F1-score in epoch 17 is 0.624\n","\n","Epoch #: 18\n","Training Loss: 1593.7945342361927\n","Epoch Time: 1m 25s\n","The bset F1 upto this point: 0.9274733965514481\n","[Results at epoch #: 18]\n","F1: [0.95932497 0.67474048]\n","Weighted F1: 0.9274733965514481\n","Precision: [0.95849546 0.67944251]\n","Recall: [0.96015591 0.67010309]\n","Confusion Matrix (Label \\ Prediction)\n","[[2217   92]\n"," [  96  195]]\n","Loss: 1593.7945342361927\n","Validation Loss: 2535.3961193561554\n","Epoch Time: 1m 25s\n","Total Time: 28m 50s\n","\n","Test F1-score in epoch 18 is 0.675\n","\n","Epoch #: 19\n","Training Loss: 1523.9373996257782\n","Epoch Time: 1m 24s\n","[Results at epoch #: 19]\n","F1: [0.95745127 0.52680653]\n","Weighted F1: 0.9092521835741286\n","Precision: [0.92770106 0.81884058]\n","Recall: [0.9891728  0.38831615]\n","Confusion Matrix (Label \\ Prediction)\n","[[2284   25]\n"," [ 178  113]]\n","Loss: 1523.9373996257782\n","Validation Loss: 3034.865405678749\n","Epoch Time: 1m 24s\n","Total Time: 30m 25s\n","\n","Test F1-score in epoch 19 is 0.527\n","\n","Epoch #: 20\n","Training Loss: 1162.5889650285244\n","Epoch Time: 1m 27s\n","[Results at epoch #: 20]\n","F1: [0.9592799  0.64419476]\n","Weighted F1: 0.9240145987023953\n","Precision: [0.94951209 0.70781893]\n","Recall: [0.96925076 0.59106529]\n","Confusion Matrix (Label \\ Prediction)\n","[[2238   71]\n"," [ 119  172]]\n","Loss: 1162.5889650285244\n","Validation Loss: 2627.5821617543697\n","Epoch Time: 1m 27s\n","Total Time: 32m 2s\n","\n","Test F1-score in epoch 20 is 0.644\n","\n","Epoch #: 21\n","Training Loss: 1112.0400492548943\n","Epoch Time: 1m 29s\n","[Results at epoch #: 21]\n","F1: [0.95905681 0.64299065]\n","Weighted F1: 0.923681709781839\n","Precision: [0.94949066 0.70491803]\n","Recall: [0.96881767 0.59106529]\n","Confusion Matrix (Label \\ Prediction)\n","[[2237   72]\n"," [ 119  172]]\n","Loss: 1112.0400492548943\n","Validation Loss: 2526.158277451992\n","Epoch Time: 1m 29s\n","Total Time: 33m 41s\n","\n","Test F1-score in epoch 21 is 0.643\n","\n","Epoch #: 22\n","Training Loss: 951.4256291389465\n","Epoch Time: 1m 26s\n","[Results at epoch #: 22]\n","F1: [0.95834233 0.65961199]\n","Weighted F1: 0.9249075086523822\n","Precision: [0.95524957 0.67753623]\n","Recall: [0.96145518 0.64261168]\n","Confusion Matrix (Label \\ Prediction)\n","[[2220   89]\n"," [ 104  187]]\n","Loss: 951.4256291389465\n","Validation Loss: 3092.561466217041\n","Epoch Time: 1m 26s\n","Total Time: 35m 17s\n","\n","Test F1-score in epoch 22 is 0.660\n","\n","Epoch #: 23\n","Training Loss: 514.3723211884499\n","Epoch Time: 1m 22s\n","[Results at epoch #: 23]\n","F1: [0.95906937 0.65949821]\n","Weighted F1: 0.9255404408056909\n","Precision: [0.95413631 0.68913858]\n","Recall: [0.9640537  0.63230241]\n","Confusion Matrix (Label \\ Prediction)\n","[[2226   83]\n"," [ 107  184]]\n","Loss: 514.3723211884499\n","Validation Loss: 3159.304440766573\n","Epoch Time: 1m 22s\n","Total Time: 36m 49s\n","\n","Test F1-score in epoch 23 is 0.659\n","\n","Epoch #: 24\n","Training Loss: 784.3481763601303\n","Epoch Time: 1m 22s\n","The bset F1 upto this point: 0.929239222413588\n","[Results at epoch #: 24]\n","F1: [0.96098297 0.67736185]\n","Weighted F1: 0.929239222413588\n","Precision: [0.95665236 0.7037037 ]\n","Recall: [0.96535297 0.65292096]\n","Confusion Matrix (Label \\ Prediction)\n","[[2229   80]\n"," [ 101  190]]\n","Loss: 784.3481763601303\n","Validation Loss: 2872.6754058897495\n","Epoch Time: 1m 22s\n","Total Time: 38m 21s\n","\n","Test F1-score in epoch 24 is 0.677\n","\n","Epoch #: 25\n","Training Loss: 761.2536457777023\n","Epoch Time: 1m 21s\n","[Results at epoch #: 25]\n","F1: [0.95797227 0.66780822]\n","Weighted F1: 0.925496216942764\n","Precision: [0.95838752 0.66552901]\n","Recall: [0.95755738 0.67010309]\n","Confusion Matrix (Label \\ Prediction)\n","[[2211   98]\n"," [  96  195]]\n","Loss: 761.2536457777023\n","Validation Loss: 3250.3134663403034\n","Epoch Time: 1m 21s\n","Total Time: 39m 52s\n","\n","Test F1-score in epoch 25 is 0.668\n","\n","Epoch #: 26\n","Training Loss: 758.5838707983494\n","Epoch Time: 1m 23s\n","[Results at epoch #: 26]\n","F1: [0.95864906 0.67125645]\n","Weighted F1: 0.926483193730029\n","Precision: [0.95844156 0.67241379]\n","Recall: [0.95885665 0.67010309]\n","Confusion Matrix (Label \\ Prediction)\n","[[2214   95]\n"," [  96  195]]\n","Loss: 758.5838707983494\n","Validation Loss: 3053.7353354096413\n","Epoch Time: 1m 23s\n","Total Time: 41m 25s\n","\n","Test F1-score in epoch 26 is 0.671\n","\n","Epoch #: 27\n","Training Loss: 388.10779121518135\n","Epoch Time: 1m 22s\n","[Results at epoch #: 27]\n","F1: [0.96193919 0.63983903]\n","Weighted F1: 0.9258887474900929\n","Precision: [0.94486216 0.77184466]\n","Recall: [0.97964487 0.54639175]\n","Confusion Matrix (Label \\ Prediction)\n","[[2262   47]\n"," [ 132  159]]\n","Loss: 388.10779121518135\n","Validation Loss: 3973.6070319116116\n","Epoch Time: 1m 22s\n","Total Time: 42m 56s\n","\n","Test F1-score in epoch 27 is 0.640\n","\n","Epoch #: 28\n","Training Loss: 299.1743649840355\n","Epoch Time: 1m 23s\n","[Results at epoch #: 28]\n","F1: [0.96076759 0.63921569]\n","Weighted F1: 0.9247785120937009\n","Precision: [0.94624108 0.74429224]\n","Recall: [0.97574708 0.56013746]\n","Confusion Matrix (Label \\ Prediction)\n","[[2253   56]\n"," [ 128  163]]\n","Loss: 299.1743649840355\n","Validation Loss: 4148.097347766161\n","Epoch Time: 1m 23s\n","Total Time: 44m 28s\n","\n","Test F1-score in epoch 28 is 0.639\n","\n","Epoch #: 29\n","Training Loss: 189.28977319598198\n","Epoch Time: 1m 23s\n","[Results at epoch #: 29]\n","F1: [0.96115046 0.66543438]\n","Weighted F1: 0.9280530078252809\n","Precision: [0.95276596 0.72      ]\n","Recall: [0.96968385 0.6185567 ]\n","Confusion Matrix (Label \\ Prediction)\n","[[2239   70]\n"," [ 111  180]]\n","Loss: 189.28977319598198\n","Validation Loss: 4089.7755163013935\n","Epoch Time: 1m 23s\n","Total Time: 46m 1s\n","\n","Test F1-score in epoch 29 is 0.665\n","\n","Epoch #: 30\n","Training Loss: 209.7424312233925\n","Epoch Time: 1m 25s\n","[Results at epoch #: 30]\n","F1: [0.9600863  0.67256637]\n","Weighted F1: 0.9279061848500804\n","Precision: [0.95657782 0.69343066]\n","Recall: [0.96362061 0.65292096]\n","Confusion Matrix (Label \\ Prediction)\n","[[2225   84]\n"," [ 101  190]]\n","Loss: 209.7424312233925\n","Validation Loss: 4218.121420502663\n","Epoch Time: 1m 25s\n","Total Time: 47m 36s\n","\n","Test F1-score in epoch 30 is 0.673\n","\n","Epoch #: 31\n","Training Loss: 541.366374284029\n","Epoch Time: 1m 26s\n","[Results at epoch #: 31]\n","F1: [0.95862069 0.65714286]\n","Weighted F1: 0.924878363016294\n","Precision: [0.95409695 0.68401487]\n","Recall: [0.96318753 0.63230241]\n","Confusion Matrix (Label \\ Prediction)\n","[[2224   85]\n"," [ 107  184]]\n","Loss: 541.366374284029\n","Validation Loss: 3802.7003232836723\n","Epoch Time: 1m 26s\n","Total Time: 49m 12s\n","\n","Test F1-score in epoch 31 is 0.657\n","\n","Epoch #: 32\n","Training Loss: 663.626875013113\n","Epoch Time: 1m 29s\n","[Results at epoch #: 32]\n","F1: [0.95836003 0.62282398]\n","Weighted F1: 0.920805799486269\n","Precision: [0.9452401  0.71238938]\n","Recall: [0.97184929 0.5532646 ]\n","Confusion Matrix (Label \\ Prediction)\n","[[2244   65]\n"," [ 130  161]]\n","Loss: 663.626875013113\n","Validation Loss: 4080.240798652172\n","Epoch Time: 1m 29s\n","Total Time: 50m 52s\n","\n","Test F1-score in epoch 32 is 0.623\n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-08656797d985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# print(label.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcausality_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"CrMAN5b_FMQs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"5d19a8b8-88f3-49b4-94b1-3d7b3e56cc72","executionInfo":{"status":"ok","timestamp":1581374748633,"user_tz":-330,"elapsed":1593,"user":{"displayName":"sronin iitk","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCphT4jhrPBxWQA7llMy2jFYOE6znf8RIqDKiQr=s64","userId":"11615430726484299494"}}},"source":["a = torch.tensor([[1,2,3],[1,2,3]])\n","a = a.unsqueeze(0)\n","print(a.size())\n","# print(a.view(1,2,3))\n","torch.sum(a,dim =1).size()"],"execution_count":167,"outputs":[{"output_type":"stream","text":["torch.Size([1, 2, 3])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3])"]},"metadata":{"tags":[]},"execution_count":167}]}]}