{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"voting of 3 transformer_baseline.ipynb","provenance":[{"file_id":"1DTbYI_bgQljngtN9b09S2znGaqUsDvu1","timestamp":1582825796897},{"file_id":"1WlpZOxP3YgwllqKn2H3rcBJuhGe6H2u3","timestamp":1582823073870},{"file_id":"1vWlKxVBu82x73C4ZI0aqsl8gXi0OTpsW","timestamp":1582730282048}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d826582003704642a244f9e5fb5e41ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ecc691742ac946ebbe542a517ea38cbe","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9d424363671349578a04fd8246639f94","IPY_MODEL_12bf5fb0b8c64eabbaf65fe81075a378"]}},"ecc691742ac946ebbe542a517ea38cbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d424363671349578a04fd8246639f94":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_57329d636a8c4699a70a361068e0391f","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd2dae251daf4e1a9d9ab4c4bbc41d25"}},"12bf5fb0b8c64eabbaf65fe81075a378":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_845a78a9c4af4c12882d24086b8184a9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 232k/232k [00:00&lt;00:00, 427kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d23a6d4541f145eeb6807c4d4b4691af"}},"57329d636a8c4699a70a361068e0391f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bd2dae251daf4e1a9d9ab4c4bbc41d25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"845a78a9c4af4c12882d24086b8184a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d23a6d4541f145eeb6807c4d4b4691af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ba56cd2cdfb4bf4882345509cef87c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a73534fb52994a349cc63484f33f819c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d90c483577cf46f1ab346803de5300ed","IPY_MODEL_09c632c1b0884b9797c4b3887a6fd456"]}},"a73534fb52994a349cc63484f33f819c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d90c483577cf46f1ab346803de5300ed":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8bc9af57a8cd4f97b179aeb765aaf99b","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":362,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":362,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2334f62b75f1418fad7e4ba376bc0e72"}},"09c632c1b0884b9797c4b3887a6fd456":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_222057aca2134f2a8fb97cfba1762b08","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 362/362 [00:00&lt;00:00, 13.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b9747e0a3494736a2bc512470bf9aa6"}},"8bc9af57a8cd4f97b179aeb765aaf99b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2334f62b75f1418fad7e4ba376bc0e72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"222057aca2134f2a8fb97cfba1762b08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5b9747e0a3494736a2bc512470bf9aa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5ecca696f1e4bf89284de2a43926c1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8f9cde4c46234c38b16bea53f17cb6fa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f22370b8f1134359b123f9f06ab330b7","IPY_MODEL_271dbf24b1c844c8a791f5ad8a998a6c"]}},"8f9cde4c46234c38b16bea53f17cb6fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f22370b8f1134359b123f9f06ab330b7":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8263a27d38a349928eb0c45dcf3e55e6","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":1344997306,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1344997306,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f24871c5b7f74ec0a930b764fe954229"}},"271dbf24b1c844c8a791f5ad8a998a6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_afba953fb4f84423be40d5d895b63cfe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 1.34G/1.34G [01:55&lt;00:00, 11.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5aa489639bb24075a68a4f8520e34601"}},"8263a27d38a349928eb0c45dcf3e55e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f24871c5b7f74ec0a930b764fe954229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afba953fb4f84423be40d5d895b63cfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5aa489639bb24075a68a4f8520e34601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"IP_74GTdyTH3","colab_type":"code","outputId":"fa6d9c65-16cf-45f2-e459-f2e8fdd4ca43","executionInfo":{"status":"ok","timestamp":1582963699056,"user_tz":-330,"elapsed":9935,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jczSOgyjyEhY","colab_type":"code","outputId":"37c64ef3-4180-474e-f9f7-ac2312ba1071","executionInfo":{"status":"ok","timestamp":1582963734124,"user_tz":-330,"elapsed":13378,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":677}},"source":["!pip install transformers\n","%cd drive/My\\ Drive/NLP"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n","\r\u001b[K     |▋                               | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 2.8MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\r\u001b[K     |▍                               | 10kB 32.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 16.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 21.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 13.5MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 10.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 9.6MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 9.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 9.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Collecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 15.2MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 39.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=859b0a174afbe3b4c6ef8b6579aacf73f3a20425bf3053ef1a25640621571c30\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n","/content/drive/My Drive/NLP\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sKb4S7vqyepJ","colab_type":"code","outputId":"2a0e401f-4f78-4523-aad5-aec2b0abf99e","executionInfo":{"status":"ok","timestamp":1582965084445,"user_tz":-330,"elapsed":8108,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":116}},"source":["from transformers import *\n","import pandas as pd\n","import numpy as np\n","import random\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","import tensorflow as tf\n","import torch.nn.functional as F\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchsummary import summary\n","from keras.preprocessing.sequence import pad_sequences\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There is/are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")\n","\n","# Set the seed value all over the place to make this reproducible. Somehow this isn't working!\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["There is/are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9vwMaus01WpY","colab_type":"code","colab":{}},"source":["MODELS = [#(BertModel,                           BertTokenizer,       'bert-base-uncased'),\n","          (BertForSequenceClassification,       BertTokenizer,       'bert-large-uncased'),\n","          #(OpenAIGPTModel,                      OpenAIGPTTokenizer,  'openai-gpt'),\n","          #(GPT2Model,                           GPT2Tokenizer,       'gpt2'),\n","          #(CTRLModel,                           CTRLTokenizer,       'ctrl'),\n","          #(TransfoXLModel,                      TransfoXLTokenizer,  'transfo-xl-wt103'),\n","          #(XLNetModel,                          XLNetTokenizer,      'xlnet-base-cased'),\n","          #(XLNetForSequenceClassification,      XLNetTokenizer,      'xlnet-large-cased'),\n","          #(XLMModel,                            XLMTokenizer,        'xlm-mlm-enfr-1024'),\n","          #(XLMForSequenceClassification,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n","          #(RobertaModel,                        RobertaTokenizer,    'roberta-large'),\n","          #(RobertaForSequenceClassification,    RobertaTokenizer,    'roberta-large'),\n","          #(XLMRobertaModel,                     XLMRobertaTokenizer, 'xlm-roberta-base'),\n","          #(XLMRobertaForSequenceClassification, XLMRobertaTokenizer, 'xlm-roberta-base'),\n","         ]\n","FIRST_DATAPATH = \"data/train_1.csv\"\n","SECOND_DATAPATH = \"data/train_2.csv\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PT9qMcQFUGG","colab_type":"code","outputId":"826544d6-29e9-4785-aa14-d149ac1d15ea","executionInfo":{"status":"ok","timestamp":1582912275688,"user_tz":-330,"elapsed":19105,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":191}},"source":["ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["bert_cnn_all.pth                         \u001b[0m\u001b[01;34msent-conv-torch\u001b[0m/\n","bertcnn.npy                              subtask1_test.csv\n","\u001b[01;34mcnn-text-classification-pytorch\u001b[0m/         train_train_1.csv\n","\u001b[01;34mdata\u001b[0m/                                    train_val_1.csv\n","\u001b[01;34mEMNLP_2018_Causal_Explanation_Analysis\u001b[0m/  wat_cosst.md\n","\u001b[01;34mroberta-large-cf\u001b[0m/                        \u001b[01;34mxlnet-base-cf-10\u001b[0m/\n","\u001b[01;34mroberta-large-cf-all\u001b[0m/                    xlnet_cnn.pth\n","roberta_large_preds_all.npy              \u001b[01;34mxlnet-large-cf\u001b[0m/\n","roberta+xlnet+bertcnn.npy                \u001b[01;34mxlnet-large-cf-all\u001b[0m/\n","roberta+xlnet.npy                        xlnet_large_preds_all.npy\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K85NYnlk6Kcj","colab_type":"text"},"source":["# For the first sub-task"]},{"cell_type":"code","metadata":{"id":"a495uYyLX4di","colab_type":"code","colab":{}},"source":["class ClassificationDataset(Dataset):\n","  def __init__(self, corpus, corpus2, tokenizer_class, pretrained_weights, max_len):\n","    self.corpus = corpus.reset_index()\n","    self.corpus2 = corpus2.reset_index()\n","    self.corpus['sentence'].dropna(inplace=True)\n","    self.tokenizer = tokenizer_class.from_pretrained(pretrained_weights)# , do_lower_case=True)\n","    self.corpus['sentence'] = [self.tokenizer.encode(sent, add_special_tokens=True, max_length=max_len) for sent in self.corpus['sentence']]\n","    self.corpus['sentence'] = pad_sequences(self.corpus['sentence'], padding='post').tolist()\n","    self.weights = torch.tensor(self.corpus2['gold_label'].value_counts(normalize=True).tolist()).to(device)\n","    # print(self.corpus['gold_label'].value_counts(normalize=True))\n","\n","  def __len__(self):\n","    return len(self.corpus)\n","\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","    # print(type(self.corpus['sentence'][idx]))\n","    X = torch.tensor(self.corpus['sentence'][idx]).to(device)\n","    y = torch.tensor(self.corpus2['gold_label'][idx]).to(device)\n","    sample = (X, y)\n","    return sample"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLoAWt5wdpzh","colab_type":"code","colab":{}},"source":["# master_corpus = pd.read_csv(FIRST_DATAPATH, encoding='utf-8')\n","# train_corpus, test_corpus = train_test_split(master_corpus, random_state=seed_val, stratify=master_corpus['gold_label'])\n","# train_corpus = pd.read_csv(\"train_train_1.csv\", encoding='utf-8')\n","test_corpus = pd.read_csv(\"subtask1_test.csv\", encoding='utf-8')\n","master_corpus = pd.read_csv(\"data/Subtask-1-master/train.csv\", encoding = 'utf-8')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPIjUJkIaGXb","colab_type":"code","colab":{}},"source":["class CustomModel(nn.Module):\n","  def __init__(self, model_class, pretrained_weights):\n","    super(CustomModel, self).__init__()\n","    self.trans = model_class.from_pretrained(pretrained_weights, output_hidden_states=False, output_attentions=False)\n","    Ci = 1\n","    Ks = [3,4,5]\n","    Co = 100\n","    self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co,(K, 1024)) for K in Ks])   \n","    self.dropout = nn.Dropout(0.5)\n","    self.fc1 = nn.Linear(len(Ks)*Co, 2) \n","\n","  def forward(self, x):\n","\n","    x = self.trans(x)[0]\n","    # print(x.size())\n","\n","    x = x.unsqueeze(1)  # not sure about this\n","\n","    x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n","    x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n","    x = torch.cat(x, 1)\n","    x = self.dropout(x)  # (N, len(Ks)*Co)\n","    logit = self.fc1(x)\n","\n","    return logit"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2dA2Hht79CF","colab_type":"code","outputId":"9fb2fd68-804b-4d45-c635-0aef00666d53","executionInfo":{"status":"ok","timestamp":1582918296690,"user_tz":-330,"elapsed":19256,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d826582003704642a244f9e5fb5e41ef","ecc691742ac946ebbe542a517ea38cbe","9d424363671349578a04fd8246639f94","12bf5fb0b8c64eabbaf65fe81075a378","57329d636a8c4699a70a361068e0391f","bd2dae251daf4e1a9d9ab4c4bbc41d25","845a78a9c4af4c12882d24086b8184a9","d23a6d4541f145eeb6807c4d4b4691af","7ba56cd2cdfb4bf4882345509cef87c2","a73534fb52994a349cc63484f33f819c","d90c483577cf46f1ab346803de5300ed","09c632c1b0884b9797c4b3887a6fd456","8bc9af57a8cd4f97b179aeb765aaf99b","2334f62b75f1418fad7e4ba376bc0e72","222057aca2134f2a8fb97cfba1762b08","5b9747e0a3494736a2bc512470bf9aa6","b5ecca696f1e4bf89284de2a43926c1d","8f9cde4c46234c38b16bea53f17cb6fa","f22370b8f1134359b123f9f06ab330b7","271dbf24b1c844c8a791f5ad8a998a6c","8263a27d38a349928eb0c45dcf3e55e6","f24871c5b7f74ec0a930b764fe954229","afba953fb4f84423be40d5d895b63cfe","5aa489639bb24075a68a4f8520e34601"]}},"source":["for model_class, tokenizer_class, pretrained_weights in MODELS:\n","  # Loading the data and splitting it\n","  # master_corpus = master_corpus\n","  train_corpus, test_corpus = master_corpus, test_corpus\n","\n","  train_dataset = ClassificationDataset(train_corpus,train_corpus, tokenizer_class, pretrained_weights, max_len=128)\n","  test_dataset = ClassificationDataset(test_corpus, train_corpus, tokenizer_class, pretrained_weights, max_len=128)\n","  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n","  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","  model= model_class.from_pretrained(pretrained_weights, num_labels=2, output_hidden_states=False, output_attentions=False)\n","  # model = CustomModel(model_class, pretrained_weights)\n","  model.to(device)\n","  criterion = nn.CrossEntropyLoss(weight=train_dataset.weights)\n","\n","  # Number of training epochs (authors recommend between 2 and 4)\n","  epochs = 10\n","\n","  \"\"\"For XLNet\"\"\"\n","  \"\"\"\n","  param_optimizer = list(model.named_parameters())\n","  no_decay = ['bias', 'gamma', 'beta']\n","  optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","  ]\n","  # This variable contains all of the hyperparemeter information our training loop needs\n","  optimizer = AdamW(optimizer_grouped_parameters,\n","                    lr=1e-5)\n","\"\"\"\n","  \n","\n","  \"\"\" For BERT \"\"\"\n","  optimizer = AdamW(model.parameters(),\n","                    lr = 1e-5, # args.learning_rate - default is 5e-5, 1e-5 worked best for me\n","                    eps = 1e-8) # args.adam_epsilon  - default is 1e-8.\n","\n","  # Total number of training steps is number of batches * number of epochs.\n","  total_train_steps = len(train_loader) * epochs\n","  # Create the learning rate scheduler.\n","  scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                              num_warmup_steps = 0, # Default value in run_glue.py\n","                                              num_training_steps = total_train_steps)\n","  \n","  for epoch in range(epochs):\n","    running_loss = 0.0\n","    total_loss = 0.0\n","    \n","    model.train()\n","\n","    train_preds = None\n","    train_labels = None\n","\n","    for i, data in enumerate(train_loader):\n","      inputs, labels = data\n","      optimizer.zero_grad()\n","      outputs = model(inputs) # labels=b_labels)\n","      # print(outputs.size())\n","      loss = criterion(outputs[0], labels)\n","      \n","      running_loss += loss.item()\n","      total_loss += loss.item()\n","      # train_accuracy += flat_accuracy(outputs[0], labels)\n","\n","      if train_preds is None or train_labels is None:\n","        train_preds = np.argmax(outputs[0].detach().cpu().numpy(), axis=1).flatten()\n","        train_labels = labels.cpu().numpy().flatten()\n","      else:\n","        train_preds = np.concatenate((train_preds, np.argmax(outputs[0].detach().cpu().numpy(), axis=1).flatten()))\n","        train_labels = np.concatenate((train_labels, labels.cpu().numpy().flatten()))\n","\n","      # Clip the norm of the gradients to 1.0.\n","      # This is to help prevent the \"exploding gradients\" problem.\n","      nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","      loss.backward()\n","      optimizer.step()\n","      scheduler.step()\n","\n","      if i % 100 == 99:    # print every 100 mini-batches\n","        print('[%d, %5d] loss: %.5f' % (epoch + 1, i + 1, running_loss / 100))\n","        running_loss = 0.0\n","    \n","    print(\"Training loss in epoch %d is %.5f\" % (epoch + 1, total_loss / len(train_loader)))\n","    print(\"Training accuracy in epoch %d is %.5f\" % (epoch + 1, accuracy_score(train_labels, train_preds) * 100))\n","    print(\"Training precision in epoch %d is %.5f\" % (epoch + 1, precision_score(train_labels, train_preds) * 100))\n","    print(\"Training recall in epoch %d is %.5f\" % (epoch + 1, recall_score(train_labels, train_preds) * 100))\n","    print(\"Training F1-score in epoch %d is %.5f\" % (epoch + 1, f1_score(train_labels, train_preds) * 100))\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    \n","    model.eval()\n","    # Tracking variables \n","    test_loss = 0.0\n","\n","    test_preds = None\n","    test_labels = None\n","\n","    with torch.no_grad():\n","      for data in test_loader:\n","        inputs, labels = data\n","        outputs = model(inputs) # labels=b_labels)\n","        loss = criterion(outputs[0], labels)\n","      \n","        test_loss += loss.item()\n","        if test_preds is None or test_labels is None:\n","          test_preds = np.argmax(outputs[0].detach().cpu().numpy(), axis=1).flatten()\n","          test_labels = labels.cpu().numpy().flatten()\n","        else:\n","          test_preds = np.concatenate((test_preds, np.argmax(outputs[0].detach().cpu().numpy(), axis=1).flatten()))\n","          test_labels = np.concatenate((test_labels, labels.cpu().numpy().flatten()))\n","\n","        # test_accuracy += flat_accuracy(outputs[0], labels)\n","    print(test_preds)\n","    # print(\"Test loss in epoch %d is %.5f\" % (epoch + 1, test_loss / len(test_loader)))\n","    print(\"Test accuracy in epoch %d is %.5f\" % (epoch + 1, accuracy_score(test_labels, test_preds) * 100))\n","    print(\"Test precision in epoch %d is %.5f\" % (epoch + 1, precision_score(test_labels, test_preds) * 100))\n","    print(\"Test recall in epoch %d is %.5f\" % (epoch + 1, recall_score(test_labels, test_preds) * 100))\n","    print(\"Test F1-score in epoch %d is %.5f\" % (epoch + 1, f1_score(test_labels, test_preds) * 100))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d826582003704642a244f9e5fb5e41ef","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ba56cd2cdfb4bf4882345509cef87c2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=362, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5ecca696f1e4bf89284de2a43926c1d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=1344997306, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","[1,   100] loss: 0.11186\n","[1,   200] loss: 0.07809\n","[1,   300] loss: 0.07050\n","[1,   400] loss: 0.04663\n","Training loss in epoch 1 is 0.07585\n","Training accuracy in epoch 1 is 89.36923\n","Training precision in epoch 1 is 90.00000\n","Training recall in epoch 1 is 5.57084\n","Training F1-score in epoch 1 is 10.49223\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 1 is 81.98571\n","Test precision in epoch 1 is 9.32897\n","Test recall in epoch 1 is 7.46073\n","Test F1-score in epoch 1 is 8.29091\n","[2,   100] loss: 0.03473\n","[2,   200] loss: 0.03139\n","[2,   300] loss: 0.02815\n","[2,   400] loss: 0.03080\n","Training loss in epoch 2 is 0.03103\n","Training accuracy in epoch 2 is 94.84615\n","Training precision in epoch 2 is 95.90164\n","Training recall in epoch 2 is 56.32737\n","Training F1-score in epoch 2 is 70.97054\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 2 is 85.18571\n","Test precision in epoch 2 is 9.25373\n","Test recall in epoch 2 is 4.05759\n","Test F1-score in epoch 2 is 5.64149\n","[3,   100] loss: 0.02166\n","[3,   200] loss: 0.02150\n","[3,   300] loss: 0.02178\n","[3,   400] loss: 0.01622\n","Training loss in epoch 3 is 0.02028\n","Training accuracy in epoch 3 is 96.78462\n","Training precision in epoch 3 is 98.14126\n","Training recall in epoch 3 is 72.62724\n","Training F1-score in epoch 3 is 83.47826\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 3 is 81.20000\n","Test precision in epoch 3 is 9.41176\n","Test recall in epoch 3 is 8.37696\n","Test F1-score in epoch 3 is 8.86427\n","[4,   100] loss: 0.00958\n","[4,   200] loss: 0.01451\n","[4,   300] loss: 0.01254\n","[4,   400] loss: 0.01186\n","Training loss in epoch 4 is 0.01214\n","Training accuracy in epoch 4 is 98.06154\n","Training precision in epoch 4 is 98.94137\n","Training recall in epoch 4 is 83.56259\n","Training F1-score in epoch 4 is 90.60403\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 4 is 82.01429\n","Test precision in epoch 4 is 9.88655\n","Test recall in epoch 4 is 7.98429\n","Test F1-score in epoch 4 is 8.83418\n","[5,   100] loss: 0.00484\n","[5,   200] loss: 0.00685\n","[5,   300] loss: 0.00941\n","[5,   400] loss: 0.00585\n","Training loss in epoch 5 is 0.00663\n","Training accuracy in epoch 5 is 99.06923\n","Training precision in epoch 5 is 99.77595\n","Training recall in epoch 5 is 91.88446\n","Training F1-score in epoch 5 is 95.66774\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 5 is 81.64286\n","Test precision in epoch 5 is 9.73725\n","Test recall in epoch 5 is 8.24607\n","Test F1-score in epoch 5 is 8.92984\n","[6,   100] loss: 0.00265\n","[6,   200] loss: 0.00368\n","[6,   300] loss: 0.00289\n","[6,   400] loss: 0.00317\n","Training loss in epoch 6 is 0.00306\n","Training accuracy in epoch 6 is 99.52308\n","Training precision in epoch 6 is 100.00000\n","Training recall in epoch 6 is 95.73590\n","Training F1-score in epoch 6 is 97.82150\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 6 is 81.62857\n","Test precision in epoch 6 is 9.72222\n","Test recall in epoch 6 is 8.24607\n","Test F1-score in epoch 6 is 8.92351\n","[7,   100] loss: 0.00233\n","[7,   200] loss: 0.00493\n","[7,   300] loss: 0.00257\n","[7,   400] loss: 0.00367\n","Training loss in epoch 7 is 0.00339\n","Training accuracy in epoch 7 is 99.54615\n","Training precision in epoch 7 is 99.85704\n","Training recall in epoch 7 is 96.07978\n","Training F1-score in epoch 7 is 97.93200\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 7 is 82.00000\n","Test precision in epoch 7 is 10.12862\n","Test recall in epoch 7 is 8.24607\n","Test F1-score in epoch 7 is 9.09091\n","[8,   100] loss: 0.00162\n","[8,   200] loss: 0.00141\n","[8,   300] loss: 0.00092\n","[8,   400] loss: 0.00112\n","Training loss in epoch 8 is 0.00125\n","Training accuracy in epoch 8 is 99.74615\n","Training precision in epoch 8 is 100.00000\n","Training recall in epoch 8 is 97.73040\n","Training F1-score in epoch 8 is 98.85217\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 8 is 80.84286\n","Test precision in epoch 8 is 9.53717\n","Test recall in epoch 8 is 8.90052\n","Test F1-score in epoch 8 is 9.20785\n","[9,   100] loss: 0.00158\n","[9,   200] loss: 0.00085\n","[9,   300] loss: 0.00103\n","[9,   400] loss: 0.00179\n","Training loss in epoch 9 is 0.00132\n","Training accuracy in epoch 9 is 99.76923\n","Training precision in epoch 9 is 99.85994\n","Training recall in epoch 9 is 98.07428\n","Training F1-score in epoch 9 is 98.95906\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 9 is 81.11429\n","Test precision in epoch 9 is 9.79827\n","Test recall in epoch 9 is 8.90052\n","Test F1-score in epoch 9 is 9.32785\n","[10,   100] loss: 0.00075\n","[10,   200] loss: 0.00042\n","[10,   300] loss: 0.00109\n","[10,   400] loss: 0.00057\n","Training loss in epoch 10 is 0.00070\n","Training accuracy in epoch 10 is 99.86923\n","Training precision in epoch 10 is 100.00000\n","Training recall in epoch 10 is 98.83081\n","Training F1-score in epoch 10 is 99.41197\n","[0 0 0 ... 0 0 0]\n","Test accuracy in epoch 10 is 81.01429\n","Test precision in epoch 10 is 9.92908\n","Test recall in epoch 10 is 9.16230\n","Test F1-score in epoch 10 is 9.53029\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"30l5C4WWcO_o","colab_type":"code","outputId":"79caf654-2afe-45c7-ae68-55159e24bc0f","executionInfo":{"status":"ok","timestamp":1582904184460,"user_tz":-330,"elapsed":2983,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"Y102aN17cSE3","colab_type":"code","outputId":"2de75b64-6276-422f-9d17-f2b36529fb82","executionInfo":{"status":"ok","timestamp":1582904214426,"user_tz":-330,"elapsed":1786,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.device('cuda:0')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"U-drXQqT2j2a","colab_type":"code","colab":{}},"source":["xlnet_large_preds = test_preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IyLq1zCS0KbN","colab_type":"code","colab":{}},"source":["xlnet_base_preds = test_preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9M3eb5yy2Ww","colab_type":"code","colab":{}},"source":["roberta_large_preds = test_preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wAF3TlZw2hJz","colab_type":"code","colab":{}},"source":["test_labels_xlnetlarge = test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKCg6d9f0PVO","colab_type":"code","colab":{}},"source":["test_labels_xlnet = test_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"94cHl1O5rPi6","colab_type":"code","colab":{}},"source":["bertcnn = np.load(\"bertcnn.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nfznfs9wrbsa","colab_type":"code","outputId":"5231b2f1-2461-4a3b-c55b-de845955a29d","executionInfo":{"status":"ok","timestamp":1582918572109,"user_tz":-330,"elapsed":2949,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(test_preds)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7000"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"J9UWlt9LRMt3","colab_type":"code","colab":{}},"source":["np.save(\"bert_large.npy\",test_preds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6suRitbvTLhy","colab_type":"code","outputId":"fa6c6156-551a-4b90-9449-8f53700d80d6","executionInfo":{"status":"ok","timestamp":1582918596074,"user_tz":-330,"elapsed":12073,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":208}},"source":["ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["bertbase.npy                             roberta+xlnet.npy\n","bert_cnn_all.pth                         \u001b[0m\u001b[01;34msent-conv-torch\u001b[0m/\n","bertcnn.npy                              subtask1_test.csv\n","bert_large.npy                           train_train_1.csv\n","\u001b[01;34mcnn-text-classification-pytorch\u001b[0m/         train_val_1.csv\n","\u001b[01;34mdata\u001b[0m/                                    wat_cosst.md\n","\u001b[01;34mEMNLP_2018_Causal_Explanation_Analysis\u001b[0m/  \u001b[01;34mxlnet-base-cf-10\u001b[0m/\n","\u001b[01;34mroberta-large-cf\u001b[0m/                        xlnet_cnn.pth\n","\u001b[01;34mroberta-large-cf-all\u001b[0m/                    \u001b[01;34mxlnet-large-cf\u001b[0m/\n","roberta_large_preds_all.npy              \u001b[01;34mxlnet-large-cf-all\u001b[0m/\n","roberta+xlnet+bertcnn.npy                xlnet_large_preds_all.npy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gB2HuaLxZB96","colab_type":"code","colab":{}},"source":["xlnet = np.load(\"xlnet_large_preds_all.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qj8LzVUaZGMa","colab_type":"code","colab":{}},"source":["roberta = np.load(\"roberta_large_preds_all.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XAtdJUZX2_bi","colab_type":"code","colab":{}},"source":["c = 0\n","for x in xlnet == roberta:\n","  if x == False:\n","    c+=1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pkhMXDn6ZFmX","colab_type":"code","colab":{}},"source":["c = 0\n","for x in bertcnn == roberta:\n","  if x == False:\n","    c+=1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N43ga1zRtkzL","colab_type":"code","colab":{}},"source":["c = 0\n","for x in preds == xlnet:\n","  if x == False:\n","    c+=1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vIi3jtcRQMl9","colab_type":"code","outputId":"0b23e6c1-2c80-410f-f1e9-3f476e3285a8","executionInfo":{"status":"ok","timestamp":1582908797506,"user_tz":-330,"elapsed":1355,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["c"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["79"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"TW4UKJbF4JDd","colab_type":"code","colab":{}},"source":["final_pred = xlnet + roberta + bertcnn  # xlnet_large_preds\n","preds = []\n","for x in final_pred:\n","  if x<1:\n","    preds.append(0)\n","  else:\n","    preds.append(1)\n","\n","\n","preds = np.array(preds)\n","\n","# print(\"Test accuracy in epoch %d is %.5f\" % (epoch + 1, accuracy_score(test_labels, preds) * 100))\n","# print(\"Test precision in epoch %d is %.5f\" % (epoch + 1, precision_score(test_labels, preds) * 100))\n","# print(\"Test recall in epoch %d is %.5f\" % (epoch + 1, recall_score(test_labels, preds) * 100))\n","# print(\"Test F1-score in epoch %d is %.5f\" % (epoch + 1, f1_score(test_labels, preds) * 100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXLX7kmbZXU8","colab_type":"code","colab":{}},"source":["np.save(\"roberta+xlnet+bertcnn.npy\", preds)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-JcGy7mFs_v","colab_type":"code","colab":{}},"source":["preds = np.load(\"roberta+xlnet+bertcnn.npy\")\n","pred1 = np.load(\"xlnet-base-cf-all-preds.npy\")\n","pred2 = np.load(\"roberta-base-cf-all-preds.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQpyrisUr0jZ","colab_type":"code","outputId":"918c88f7-afbd-4208-c70c-5079dfbd110a","executionInfo":{"status":"ok","timestamp":1582908702803,"user_tz":-330,"elapsed":2563,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["preds"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"jgRYtDMWr1nA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IT-M-g-s20sC","colab_type":"code","colab":{}},"source":["final_pred = bertcnn + xlnet + roberta + pred1 + pred2\n","preds_all = []\n","for x in final_pred:\n","  if x<2:\n","    preds_all.append(0)\n","  else:\n","    preds_all.append(1)\n","\n","\n","preds_all = np.array(preds_all)\n","\n","# print(\"Test accuracy in epoch %d is %.5f\" % (epoch + 1, accuracy_score(test_labels, preds) * 100))\n","# print(\"Test precision in epoch %d is %.5f\" % (epoch + 1, precision_score(test_labels, preds) * 100))\n","# print(\"Test recall in epoch %d is %.5f\" % (epoch + 1, recall_score(test_labels, preds) * 100))\n","# print(\"Test F1-score in epoch %d is %.5f\" % (epoch + 1, f1_score(test_labels, preds) * 100))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZuTBpEVHGSW","colab_type":"code","colab":{}},"source":["np.save(\"all_preds_2.npy\", preds_all)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"biI-Z0ogHKnc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d72c0e48-8dab-4db5-d045-77922447460a","executionInfo":{"status":"ok","timestamp":1582966186730,"user_tz":-330,"elapsed":1074,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}}},"source":["c = 0\n","for x in preds_all == roberta:\n","  if x == False:\n","    c+=1\n","print(c)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xBm8rFuBP87a","colab_type":"code","outputId":"3ae91256-b271-473a-e6fa-0559fe1439da","executionInfo":{"status":"error","timestamp":1582757426438,"user_tz":-330,"elapsed":3478,"user":{"displayName":"Rohin Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64","userId":"03455532354584450462"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["model.save_pretrained('xlnet-base-cnn')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-b5a9412b0759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xlnet-base-cnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'CustomModel' object has no attribute 'save_pretrained'"]}]},{"cell_type":"code","metadata":{"id":"WaDNTR02O3Mm","colab_type":"code","outputId":"9e5f6d30-f328-4fd1-bf2e-c3ef6fb1e4af","executionInfo":{"status":"error","timestamp":1582644302359,"user_tz":-330,"elapsed":1619,"user":{"displayName":"Shashank Gupta","photoUrl":"","userId":"02574039063615610097"}},"colab":{"base_uri":"https://localhost:8080/","height":244}},"source":["class FilteringDataset(Dataset):\n","  def __init__(self, corpus, tokenizer_class, pretrained_weights, max_len):\n","    self.corpus = corpus.reset_index()\n","    self.corpus['sentence'].dropna(inplace=True)\n","    self.tokenizer = tokenizer_class.from_pretrained(pretrained_weights)# , do_lower_case=True)\n","    self.max_len = max_len\n","    # self.corpus['sentence'] = [self.tokenizer.encode(sent, add_special_tokens=True, max_length=max_len) for sent in self.corpus['sentence']]\n","    # self.corpus['sentence'] = pad_sequences(self.corpus['sentence'], padding='post').tolist()\n","    self.weights = torch.tensor(self.corpus['gold_label'].value_counts(normalize=True).tolist()).to(device)\n","    print(self.corpus['gold_label'].value_counts(normalize=True))\n","\n","  def __len__(self):\n","    return len(self.corpus)\n","\n","  def __getitem__(self, idx):\n","    if torch.is_tensor(idx):\n","      idx = idx.tolist()\n","    # print(type(self.corpus['sentence'][idx]))\n","    sentence = self.corpus['sentence'][idx]\n","    tok_seq = self.tokenizer.encode(sentence, add_special_tokens=True, max_length=self.max_len)\n","    while len(tok_seq) < self.max_len:\n","      tok_seq.append(0)\n","    X = torch.tensor(tok_seq).to(device)\n","    y = torch.tensor(self.corpus['gold_label'][idx]).to(device)\n","    sample = (X, y, sentence)\n","    return sample"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ad9690ae417e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mFilteringDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# , do_lower_case=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"]}]},{"cell_type":"code","metadata":{"id":"PX5xiyQ7HwcL","colab_type":"code","outputId":"2b9d0023-9618-4076-dddc-7dd6ee136470","executionInfo":{"status":"ok","timestamp":1582278357076,"user_tz":-330,"elapsed":3960,"user":{"displayName":"Shashank Gupta","photoUrl":"","userId":"02574039063615610097"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!nvidia-smi -r"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPU Reset couldn't run because it failed to allocate group of reset devices : Uninitialized\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PwzZcHbHK_OG","colab_type":"code","outputId":"705e1da4-d2a5-40bf-a7e8-d11a33ad4e69","executionInfo":{"status":"ok","timestamp":1582541427513,"user_tz":-330,"elapsed":171928,"user":{"displayName":"Shashank Gupta","photoUrl":"","userId":"02574039063615610097"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["for model_class, tokenizer_class, pretrained_weights in MODELS:\n","  # Loading the data and splitting it\n","  master_corpus = pd.read_csv(\"data/train_1.csv\")\n","  master_dataset = FilteringDataset(master_corpus, tokenizer_class, pretrained_weights, max_len=128)\n","  master_loader = torch.utils.data.DataLoader(master_dataset, batch_size=1, shuffle=True)\n","  criterion = nn.CrossEntropyLoss(weight=master_dataset.weights)\n","\n","\n","  model = model_class.from_pretrained('bert-base')\n","  model.cuda()\n","  \n","  FP = []\n","  FN = []\n","\n","  test_loss = 0\n","  test_preds = None\n","  test_labels = None\n","  for i, data in enumerate(master_loader):\n","    inp, labels, sent = data\n","    outputs = model(inp) # labels=b_labels)\n","    loss = criterion(outputs[0], labels)\n","      \n","    test_loss += loss.item()\n","    preds = np.argmax(outputs[0].detach().cpu().numpy(), axis=1).flatten()\n","    labels = labels.cpu().numpy().flatten()\n","    if test_preds is None or test_labels is None:\n","      test_preds = preds.copy()\n","      test_labels = labels.copy()\n","    else:\n","      test_preds = np.concatenate((test_preds, preds))\n","      test_labels = np.concatenate((test_labels, labels))\n","\n","    for i in range(preds.shape[0]):\n","      if preds[i].item() is 0 and labels[i].item() is 1:\n","        FN.append(sent[i])\n","      elif preds[i].item() is 1 and labels[i].item() is 0:\n","        FP.append(sent[i])\n","\n","  print(\"Test loss in epoch %d is %.5f\" % (1, test_loss / len(master_loader)))\n","  print(\"Test accuracy in epoch %d is %.5f\" % (1, accuracy_score(test_labels, test_preds) * 100))\n","  print(\"Test precision in epoch %d is %.5f\" % (1, precision_score(test_labels, test_preds) * 100))\n","  print(\"Test recall in epoch %d is %.5f\" % (1, recall_score(test_labels, test_preds) * 100))\n","  print(\"Test F1-score in epoch %d is %.5f\" % (1, f1_score(test_labels, test_preds) * 100))\n","\n","  for i in FP:\n","    print(i)\n","  print()\n","  for i in FN:\n","    print(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0    0.888154\n","1    0.111846\n","Name: gold_label, dtype: float64\n","Test loss in epoch 1 is 0.04509\n","Test accuracy in epoch 1 is 99.12308\n","Test precision in epoch 1 is 96.65738\n","Test recall in epoch 1 is 95.46080\n","Test F1-score in epoch 1 is 96.05536\n","As at DocX, the assignments were signed years after the mortgages should have been transferred to the investment trusts.\n","But it should have been clear that rules allowing retaliation against alleged currency manipulators, which would almost certainly fall foul of World Trade Organisation law, were a non-starter.\n","The 10 operations I had as a child and adolescent left scars on my ankles, knees, hips and shoulders that remind me daily of what was once there that should not have been.\n","Ashley Halsey from the Post: \"The Federal Aviation Administration would have had 180 days to come up with regulations on the width, padding and leg room each seat should provide.\n","While the overall Medicaid budgets were routinely exceeded and that should have caused legislators to realize that something in their PCMH was amiss, Milliman fabricated data to pretend the PCMH program was a success.\n","And now Higgins is back at \"searching the boxes\" because he's going to claim again that they should have been turned over for evidence, even though Cohen already said these are documents that were returned by investigators.\n","Brian noted BP employees had referred to Macondo as a \"well from Hell\" in emails, and the inaction following Vidrine and Hafle's 8-minute phone call showed they did what BP had done for two months in the face of a risky well: \"They did nothing.\" Halliburton's lawyer, Don Godwin, made similar arguments about BP but also said Transocean's rig crew should have shut in the well at the first sign of trouble.\n","It's impossible to tell from the CMS report if these goals were accomplished as quickly as they should have been.\n","As security director, Mr. Wolfe would have been responsible for ensuring that those rules were upheld.\n","I wish our payers of all types would be a bit more creative in allowing for services alternatives as the first line of expense, rather than the last ditch effort when other expensive things have failed.\n","The difficult dollar comparisons [and] weak global growth have really weighed on the growth this year, and if earnings growth this year were only 5 percent, the price-to-earnings multiple should be around 16, 17 times.\n","Let me ask you a question: This would have been a good opportunity for Shaheen to clear up with what, if anything, Brown did to scuttle her energy efficiency bill in the Senate.\n","I thought that if I was just doing what the doctor said, I'd be fine.\n","Many were astounded that he should have died over something so trivial.\n","team was in Tripoli they were not in Benghazi, it would not have made any difference in Benghazi.\" The U.S.\n","Using simple math, you'd think that if you had worked 33 years and chose to work one more year, then you'd boost your benefits by about 1/33, or 3%.\n","Legal experts say any deal taking BlackBerry private would work best if it had Canadian involvement.\n","If it took a Richard Nixon to go to China, maybe Trump could have restored environmental sanity to the Republicans.\n","\"Most investors would have been happy if they got it at 10 percent growth,\" said Moran.\n","If that were a precursor to a big blue wave, it would give the opposition party control of the House.\n","Herman Cain claims that if he were the nominee he would have a substantial lead over Barack Obama.\n","She wouldn't have baked a cake with non-biblical anti-gay epithets, either.\n","If blogger Dr. Kevin Pho had his way, more doctors would be like Malcolm Gladwell, author of (most recently) David and Goliath.\n","Then, in a routine that would be comically unbelievable were it not a mirror image of the way Giuliani has addressed a whole series of issues, he first claims that \"you can't really question why the president would say something.\" Then says it's all fine ...\n","If these cracks were present on the inner surface of the column when the crane was recertified following the collision and during subsequent annual inspections, they would have been difficult to detect given the limitations of the magnetic particle inspection technique used for crane inspection and the location of the cracks.\n","'Well, as my mother would say, Tim, if she were here, \"Sweetheart, we should have such a problem.\"' He went on to say that he would probably stay near the Capitol on Friday night, to avoid having to travel by car.\n","Arguably, that would be true even if the EU did not exist: in a world of global capital, ownership becomes diffuse and fuzzy in any case.\n","\"Before, if VA employees spoke out against the Cerner deal they might have been worried about losing their jobs, but if they were ready to retire they might have taken the chance,\" said Nancy Anthracite, director of WorldVista, which commercializes VistA-based software.\n","If the payment were to be deemed campaign-related, the Trump campaign should have disclosed it in its periodic filings with the F.E.C., as soon as Mr. Trump or his campaign learned that Mr. Cohen had made it.\n","After all, there were so many factors - Comey, Russia, the Clintonness of it all, Jill Stein - that could have explained away our descent into openly bigoted authoritarianism.\n","I will miss not having a national audience for this blog and I do very much wish that there were a national network for health bloggers.\n","\"The controls and procedures that should have been in place, were not in place.\" Wachovia said it increased its first-quarter loss by $315 million after reviewing $360 million of stable value agreements provided by a third-party guarantor.\n","In the debates regarding health care reform, one goal promoted by all is \"quality.\" If only we could perform up to standards, the institution of American medicine would be supreme and vindicated.\n","I am now 40 and don't wish I had known anything more than I did at the time.\n","Overall, these two studies provide compelling evidence that people improved the honesty of their behavior on Facebook because they have heard about and signed the pledge, and there is no reason to believe they would have improved if they did not hear about and sign the pledge.\n","It would be better, then, if parliament gave the TPR the resources and the authority preemptively to enforce conditions on corporate deals involving schemes that are in deficit.\n","On Thursday, he said that if Najib had done anything wrong he would \"face the consequences\".\n","CARVILLE: There was some kind of sense that if I was out there, then you don't need to be.\n","Were they to succeed, the GOP wouldn't just be preventing up to 30 million more people in the U.S.\n","When Ader and Karen Olness published Marette's case, they were careful to say there was no proof that she wouldn't have done just as well without the conditioning.\n","I was curious about whether other women felt the same way I did - encouraged by the uptick in female candidates yet exasperated that the phenomenon is still characterized as some chromosomal anomaly that couldn't have happened without a man.\n","'I did what any other teacher would have done and I know there were others like me doing the same.\n","If you choose to take Social Security at 62 and your FRA is 67, the amount you'll receive will be 30% lower than it would be if you had waited until 67.\n","Even if the Prime Minister's deal had been passed on Tuesday, there is a huge raft of legislation the Government would still need to pass.\n","\"If President Barack Obama had the legal authority to use his discretion to create DACA in the first place\", Mr Feldman reasons, \"Mr Trump must have the legal authority to reverse DACA on the ground that he considers it to have exceeded Mr Obama's powers.\" It is \"cute\" for Judge Alsup to cite a tweet from Mr Trump frowning on \"throw[ing] out good, educated and accomplished young people who have jobs, some serving in the military\" to show that the president \"publicly favours the very programme the agency has ended\"-but this is neither here nor there, Mr Feldman writes.\n","The neuroscientists discovered that the same neuron that fires for one image (i.e. Jennifer Aniston) would also fire instantly for another image (i.e. Eiffel Tower) if the study participant had been shown an image of Jennifer Aniston standing in front of the Eiffel Tower.\n","Clearly there were no underlying disorders as they should have been treated first.\n","(And then your problems weren't really all that fundamental in the first place, or you wouldn't have had the power to cure yourself...not all of us are that lucky.) Therapists have no knowledge to offer you, and no real talent to change anything about your life.\n","\n","\"We're certainly on board with the notion that if all the economic, geopolitical, lowflationary, and cyclical headwinds were removed, rates would be higher and stocks soaring (more) - but that hasn't proven to be this year's trade,\" wrote Ian Lyngen, head of US rates strategy at BMO Capital Markets, in a morning note.\n","Its headline conclusion is that UK spending on healthcare will have to rise by an average of 3.3 per cent a year over the next 15 years just to maintain NHS provision at current levels, and by at least 4 per cent a year if services are to be improved, since this is such an expensive proposal, but at least it does not have to grow by a million percent if it is to be turned into a program that can cover everyone on Earth.\n","For example, Pinal County in Arizona might have no insurer selling marketplace policies for 2017 unless another company comes in and wipes any trace of Aetna from existence and completely replaces it.\n","According to simulations by Nate Silver, a data guru, if only women voted, Mrs Clinton would win with 458 electoral college votes to Mr Trumps 80.\n","There's no record of her registering to be a donor before she died, yet assuming that she decided to do so while she was alive, someone being saved as a result was a real possibility.\n","It's exciting, because it appears that we can deliver toxic agents where we want them and nowhere else, and this concept may have applicability to other drugs other than chemotherapeutic agents, but in different circumstances where it did not appear so, it would be a major disappointment.\n","\"If a Romney-Obama matchup were held today, registered voters would divide 51 percent for the president to 44 percent for the former Massachusetts governor,\" The Washington Post reported on Tuesday.\n","Would Trump benefit if Russia had greater control of areas in Ukraine or the Balkans? We don't know.\n","In the worst cases, the regulator found customers were waiting \"hundreds of working days\" for switches that could have been conducted in a few days or weeks.\n","Stop beating yourself up for all the things you could have done or should have done.\n","He erred, first, in allowing semi-pro agitators to lure him into an exchange about corporations when he should have had the presence of mind to calmly clarify that to increase or eliminate the cap on the payroll tax is just what he said it is: to raise taxes on people.\n","I'd struggle more if I had time to dwell,\" Golbon said.\n","has already ousted Ghosn as chairman, and CEO Hiroto Saikawa has told French media that Renault would reach the same conclusion if it had access to all relevant information.\n","The agency started to warn about the gloves in 1997 but refrained from banning them then, largely because it determined that pulling them from the market at the time could have caused shortages and been disruptive to the practice of medicine.\n","Samana said consumers might feel better about their relationship with big tech if they had more chances to decide how they want their data to be used, and, pending the development of strategies which would allow them to do so, the companies could gain a new revenue stream if they give users an opportunity to pay them not to collect or sell some personal information.\n","Previously, Republicans might have viewed this projection as a triumph.\n","Mr. Stan, the state health department spokesman, said the local health director would have been responsible for delivering any quarantine order signed by the state health commissioner, though this just a theory since no orders were issued.\n","He could, for instance, have urged the House to pass the Senate health bill, which is imperfect but better than nothing; or he could have reached out to Republicans by offering compromises.\n","If Congress was doing its job of regulatory oversight, they would sponsor hearings to learn what payers and providers are actually spending on ICD-10 conversion.\n","\"If I could wave a magic wand and change (the start) from 2014 to 2015, I would,\" said Sandy Praeger, Kansas' elected insurance commissioner, whose plan for a state partnership exchange was rejected by Gov. Sam Brownback.\n","Even if the late saver continued putting away that same amount as scheduled until age 30, they'd still come up short unless they found a way for money to multiply on its own.\n","Luckily, the municipality had the funds to fly him there; by boat, the only other means of transport, the journey would have taken seven days.\n","\"\"The entire drug scene has changed so much that strategies we might have employed even 10 years ago aren't relatable today, so unless time stands still, we have to constantly upgrade our strategies\" he said.\"\n","The show had aired a rerun the night before featuring a sketch imagining what life would be like if he had never become president.\n","\"An imminent year ago, I could not have imagined that I'd be here,\" Watkins says.\n","In all, patients taking the drug lost only between 3% and 3.7% of their body weight beyond what they would have with a placebo, the study showed.\n","Reproductive rights The UN's World Population Report said countries must strengthen women's reproductive rights because if progress was to continue on cutting family size and if all fertility problems could be wiped from ever existing it would drastically reduce population growth problems, since global population would be set to grow another 2.2bn by 2050.\n","Yeah, and there would be no STI's if every person on the planet had sex with no more than one person in their life.\n","Walter White, protagonist of the US TV drama, would receive free treatment for cancer if he was from St Albans, not Albuquerque.\n","\"I would be concerned if I were a producer relying on that market, given the upcoming circumstances that will affect it,\" said exporter Greg Corra, who runs Inland Trading Co from his farm outside Canberra.\n","\"In each of those instances I remember thinking while sitting in the emergency room what would have happened if I didn't have reliable health care,\" the president said.\n","An early look at data from California suggested that presuming the thimerosal weren't removed, there might not have been a decline in autism.\n","If these practices are indicators of a more aggressive approach to end-of-life care in general or can make someone immortal, then you would wonder why health care professionals spend more time talking to white families about their options.\n","If Shire's 60 per cent jump in third-quarter profits would come days after the collapse of its proposed £32bn merger with AbbVie, an actual impossible event, the fears that the company might have been distracted during the turbulent past few months would have been confounding.\n","That meant he could not attend the meeting of parliament that would have elected him president, and legally he could not be named unless he was present.\n","I would feel the same if the roles were reversed ie, husband had done it to his wife.\n","\"Can you imagine if I said the things she said?\" Mr. Trump told the crowd.\n","\"So even if he can spend infinite money, it doesn't follow that he can use that money to condemn property,\" Somin said, adding that the administration would then be limited to building the predicted wall on land the federal government already own.\n","He was doing so much exercise he would have won a gold star in most wellness programmes but in fact he was burning out.\n","The Advocate, meanwhile, Louisiana's largest newspaper, complained in an editorial that Barack Obama was still sunning himself in Martha's Vineyard when he should have been touring the damage; though the paper conceded that Obama's first responders were doing a much better job with this storm than their predecessors did after Hurricane Katrina in 2005.\n","Unless your body magically cures itself from diabetes, meaning you wouldn't require treatment, your blood sugar will go up, but then once you take your medicine again, it'll be fine.\n","Moreover, if addiction resides in the parts of the brain involved in love, then recovery is more like getting over a breakup than it is like facing a lifelong illness, but if addiction is bound to one's soul, then treatment is like getting an exorcism.\n","Before they took Entresto, and pending a diagnosis that would have counter-indicated using Enestro, patients should have told their doctor about all of their medical conditions, including if they had kidney or liver problems; or a history of hereditary angioedema; were pregnant or planned to become pregnant; were breastfeeding or planned to breastfeed.\n","Between March and July, the report says, if the reproduction number in Guinea were to hover around 1, which is not feasible given the humongous average, it would be good, and there would not be a need for; \"modest further intervention efforts that could achieve control\".\n","That argument might make sense if the company had capacity issues -- and it has admitted in the past that it doesn't -- or if hadn't previously offered unlimited data.\n","Monaco, MD, who had his voice box removed due to cancer seven years ago, says he would consider having a transplant if he were younger.\n","Even if the Juul craze carries on, it would only become a serious hazard if vapers progressed to smoking as a consequence of obtained a nicotine addiction from the Juul.\n","Chen had called the offer of up to $100 million for the impending larger class neither fair nor adequate; some drivers would have made as little as $12 with its acceptance.\n","And there's no guarantee of bucking the flu even if you get the shot, unless that shot happens to be a magic cure-all.\n","Kidd said as archbishop Pell would have \"cast a powerful shadow\" and thought he could control the situation if caught.\n","Even if the 538 electors were somehow men and women of profound virtue and valour, blessed with a deep understanding of what America needs in a president, it would still be antithetical to democratic principles to untether their vote from the results of the actual vote on election day.\n","However, she suggests that the authors could have used a lower threshold than five drinks at a time to define heavy drinking.\n","Chris says: \"Perhaps when people like teachers were first being priced out of London, we should have realised that a decade or so later these forces would affect us too.\" But he questions whether the 1980s and 1990s, when his cohort had it so good, really were a golden past whose norms can be recaptured.\n","Even if they could, I would still oppose them on moral grounds.\n","It's become fashionable to tell a disability story in a hopeful arc, where the heroine may have moments of discouragement or fear, but comes out into full life at the end - into mainstream schools, love and romance, full participation in the social world, and these stories have become so pervasive that if they were to spread to aliens they'd find them familiar.\n","This makes sense to me; I'm interested in this area of study because I believe that my mother would have scored somewhere in the mid-range of the PCL (the subclinical range.) She had a lot of NPD traits, and some antisocial traits although she never did anything blatantly criminal enough to get arrested for.\n","If investors could forecast future economic growth, then Goldman would be right: superior returns would be achieved.\n","\"We had hoped the Democrats would negotiate, but their base will roast them alive if they supported\" a compromise deal unblocking Trump nominees, said Senator John Cornyn, Republican of Texas, who is a close ally of Mr. McConnell..\n","As I say, I would have thought this track record would have been enough to put an end to Case's political ambitions, but ambition is what defines Ed Case-ambition, and douchiness.\n","Also at the news conference on Friday, a former president of the society, said that a paper delivered at the Thursday meeting may have violated the society's rules that no organs from executed prisoners be used in research even if they made a device that could remove organs without any kind of surgery, painlessly and covertly.\n","If elections were held today, polls show that the coalition would fall short of a majority in parliament, giving Mr Strache a chance to become chancellor.\n","anyone who would have legitimately earned that title would not behave the way you have, that means you are a fraud, trying to us MD to make yourself seem smarter because you are not.\n","The Nazis concluded that if Roosevelt could be replaced by a non-interventionist, the prospects of US involvement in the European war would be greatly reduced.\n","I think marijuana has a lack of evidence behind some things for benefit and may have some downsides, but I do not think marijuana, per se, is a highly risky therapy, but on the otherhand if I thought it was, I could never recommend it.\n","Early research has even suggested that the 'placebo effect' could have therapeutic results on a whopping 35% of patients, but a new study casts doubt on the placebo's power to act as though it is a miracle cure.\n","Shire demanded that AbbVie should include a reverse break fee as part of an agreed upon deal in effect creating a hefty penalty for AbbVie if it were to give up the chance that no one would miss.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T2cZqgtOjNM4","colab_type":"code","outputId":"b5e89bd9-6a4f-4e85-e2c0-ab8df40335f6","executionInfo":{"status":"ok","timestamp":1582541956098,"user_tz":-330,"elapsed":1329,"user":{"displayName":"Shashank Gupta","photoUrl":"","userId":"02574039063615610097"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["print(len(FP))\n","print(len(FN))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["48\n","66\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hGQTsy0VYsfH","colab_type":"code","outputId":"66885b84-751b-495c-ffaa-72a3d46fad8a","executionInfo":{"status":"ok","timestamp":1582279897461,"user_tz":-330,"elapsed":1037,"user":{"displayName":"Shashank Gupta","photoUrl":"","userId":"02574039063615610097"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["print(FP[np.argmin([len(x) for x in FP])])\n","print(FP[np.argmax([len(x) for x in FP])])\n","print(FN[np.argmin([len(x) for x in FN])])\n","print(FN[np.argmax([len(x) for x in FN])])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["I thought that if I was just doing what the doctor said, I'd be fine.\n","The decision has been criticised by opponents, who say that rather than thinking about how the law would affect people like himselfwell-off, white, well-educatedthe governor ought to have thought about less privileged folk, who might find themselves under pressure from relatives or health-care providers to take a quick and cheap way out.\n","Yet it could have been far worse.\n","It's become fashionable to tell a disability story in a hopeful arc, where the heroine may have moments of discouragement or fear, but comes out into full life at the end - into mainstream schools, love and romance, full participation in the social world, and these stories have become so pervasive that if they were to spread to aliens they'd find them familiar.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DA6QWmEYjTBN","colab_type":"code","outputId":"5018d9e6-97c3-494d-ec1e-2fcb00cf64e2","executionInfo":{"status":"ok","timestamp":1582201399218,"user_tz":-330,"elapsed":1267,"user":{"displayName":"Shashank Gupta","photoUrl":"","userId":"02574039063615610097"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["print(len(FP))\n","print(len(FN))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["132\n","1441\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8tx1lzuEGVr6","colab_type":"code","outputId":"40c712e4-7ff5-4fdb-b0ef-2f2d711a950f","executionInfo":{"status":"ok","timestamp":1582541082413,"user_tz":-330,"elapsed":6317,"user":{"displayName":"Shashank Gupta","photoUrl":"","userId":"02574039063615610097"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["!pip install tensorflow-hub\n","import tensorflow_hub as hub"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (3.10.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.12.0)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub) (1.17.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub) (45.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F9XaLda-zHVq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}